# SLURM - заметки

# Docker

Хорошая практика - запускать процессы внутри контейнера в foreground (при этом сам запущенный контейнер может работать и в background)
Слои в образе - readonly
.dockerignore - указывать директории, которые не надо класть в образ
Отключение кэшей - для пакетных менеджеров и для сборщиков типа pip
Например для APT внутри директивы установки пакетов - добавить

`RUN apt-get update && apt-get install ... && rm -rf /var/lib/apt/lists/*`

Концепция контейнеров не предполагает заходить внутрь контейнера для сбора и прочтения логов - логи пишутся в stdout/stderr
Все что контейнер написал в stdout/stderr - docker переведет в JSON, добавит метаинформацию и сложит на хосте в определенную директорию
Для того чтобы ловить логи nginx из стандартных файлов куда он их складывает - можно добавить директиву

`RUN set -ex && \
	ln -sf /dev/stdout /var/log/nginx/access.log && \
	ln -sf /dev/stderr /var/log/nginx/error.log`

set -ex - это чтобы видеть, какие команды в какой момент выполняются
Разница между COPY и ADD - ADD может скопировать файлы из удаленного источника, разархивировать архив и так далее. Если надо просто скопировать файл с хоста в контейнер - проще использовать COPY.
Разница между ENTRYPOINT и CMD - последняя чаще всего используется так же как ENTRYPOINT, но есть нюансы
ENTRYPOINT - должен использоваться при старте контейнера
CMD - добавлять параметры для энтрипойнта
То есть запуск приложения - через ENTRYPOINT, а ключи для запуска передать в CMD

Docker не про контейнеры. Docker про стандартизацию поставки и распространению ПО.
Воспроизводимость, консистентность.

Docker engine - это демон
Запущен как обычный процесс
docker build, ps, run - консольные утилиты, передают GRPC-команды на докер-демон
На том же хосте утилита обращается в UNIX-сокет локальной машины

Docker registry - хранилище images

## Namespace Isolation

Namespace - механизм изоляции процессов друг от друга, вшит в ядро Linux - PID, Net, Mount, User
  - PID NS - пространство имен айди процессов. PID 1 - это корневой процесс, без него работа системы завершается. Если скрипт внутри контейнера конечный - контейнер завершается (по умолчанию запуск под PID 1).
  - NET NS - сетевое окружение: сетевые интерфейсы (+lo), route tables, iptables, sockets
  - в один NS можно добавлять несколько процессов (например несколько контейнеров объединить общим localhost через который контейнеры могут общаться)
  - MNT NS - своя root fs, свои приватные маунты
  - правила сетевого NS можно тюнить в части параметров sysctl для каждого контейнера отдельно
  - USER NS - позволяет мапить GID/UID с хоста

Докер это в первую очередь система упаковки и доставки, а не обеспечения безопасности и защиты контейнеров.
Докер не обеспечивает суперизоляцию процессов и их безопасность, это скорее про ВМ или физику.

CGroups - механизм изоляции вычислительных ресурсов процессов друг от друга - CPU, Memory, I/O, Net
  - добавляют overhead - или нет. В зависимости от ситуации

Copy-On-Write - тоже механика ядра Linux. При чтении используется общая копия, при записи - новая копия. Используется также в LXC

## Storage-драйверы

  - самые популярные - overlay, devicemapper, AUFS
  - devicemapper - в CentOS дефолтный до недавнего времени, работает через loopback, надо использовать в версии с SYN-пулами. 
  - overlay - хорошая поддержка лишь в ядре 4.X. Поддерживается в ядре от 3.10 - CentOS 7.4. Для 7.4 рекомендуется overlay2.
  - для Ubuntu и Debian - лучший драйвер это AUFS.
  - BTRFS/ZFS - первый не развивается, второй под Linux практически тоже. 

## Log-драйверы.

  - по умолчанию - JSON-файл, со своей задачей справляется.
  - journald - из системного журнала. Нужно тюнить, лимиты по умолчанию на прием логов скромные. Плюс к тому есть хард-лимиты - выше определенных значений его не затюнить и поэтому лучше его не использовать.
  - syslog - по UDP/TCP/TLS
  - fluentd - по TCP, можно собирать логи из всех источников одновременно
  - ETW -> Windows Event Store
  - Splunk
  - Geif
  - Logentries
  - Amazon CloudWatch
  - Google Cloud
  - из драйвера логи попадают в log shipper.
  - рекомендуется для Docker остаться на JSON-файле (не теряя возможности выполнять docker logs), собирать логи через fluentd, потом в ElasticSearch + Kibana для просмотра.

Полезные опции
  - dockerd --default-ulimit - аналог docker run -ulimit, переопределяет максимальное число процессов, которые может запускать контейнер.
  - --dns - переопределять DNS-серверы
  - --insecure-registry - если свой реестр без сертификата, по умолчанию docker не даст подключиться к реестру без TLS.

## Docker Compose

Это обертка на Python над Docker - позволяет по описанию в YAML запускать многоконтейнерную структуру.

В 3 версии файла (версия декларируется параметром version: в YAML) выпилили поддержку healthcheck-ов и зависимостей.

healthcheck:
  test: ["CMD", "команда", "параметры"]
  interval: 1s
  timeout: 1s
  retries: 60

Healthcheck - это команда, которая должна возвращать нулевой exit-код. Если не возвращает - повторяется с нужным интервалом, после нужного таймаута и нужное количество раз.

docker-compose.override.yml - применяется автоматически при docker-compose up без указания дополнительных файлов.
Как пример - можно описать пробрасываемые порты и подключаемые тома с локального хоста при локальной разработке.
docker-compose.test.yml - нужно руками указывать docker-compose up -f <файл>. Оверрайд при этом отключается.
Как пример - использование переменных для тестового окружения.

## Docker registry

Альтернативные продукты - Harbor
  - хранение образов
  - авторизация
  - ротация
  - сканирование 
  - hook API
  - хранение других сущностей

Можно указать альтернативный registry в docker run, по умолчанию образы берутся с hub.docker.io

## Лучшие практики, паттерны и антипаттерны

Файлы, где описаны зависимости - копируются в начале
Логично что после копирования файлов - надо делать установку зависимостей, а потом копировать сам код.
Если копировать скрипты например из Debian на Alpine - то надо следить как именуются пользователи. В Debian nginx запускается под пользователем www-data, в Alpine - под nginx.
Добавляя пользователя внутрь контейнера - усложняется процесс сборки, если можно без этого обойтись - то надо обходиться.

Update делать нормально, upgrade - нет, так как это плохое, непредсказуемое поведение. При каждой сборке образа будет апгрейд пакетов, и что-то может поломаться.

Dev-пакеты для того чтобы собрать зависимости - лучше не делать в образе, в котором будет запускаться приложение. Лучше их собирать в новый базовый образ.

Надо отключать кэши и не тащить в образ.

Пакеты надо ставить до добавления кода, если так не делать - любое изменение кода будет вызывать повторную выкачку и установку пакетов.

Бандлы пакетов лучше выносить в переменные и указывать в начале Dockerfile, чтобы можно было потом легко вносить изменения:

`ARG BUILD_PACKAGES="nginx nodejs dcron tzdata postgresql-dev libxslt-dev"`

Статику можно собирать либо в Dockerfile, либо в ENTRYPOINT.
Лучше в Dockerfile, так как контейнеры могут падать, рестартоваться, а смысл контейнеров - как можно быстрее поднять работающее приложение.

В идеале 1 контейнер = 1 процесс. В реальной жизни часто приходится искать компромиссы. 

Приложения надо адаптировать. Если приложение не писалось под Docker - есть ненулевая вероятность, что оно не будет нормально работать. Пример - Java 7, которая не могла правильно определять количество процессоров внутри контейнера.

Архитектуру надо прорабатывать - как с точки зрения инфраструктуры, так и с точки зрения приложений и взаимодействия между ними. Как пример - делить приложение на фронт и бэк с общением между ними по HTTP.

Docker надо мониторить, причем не так как сервера. Контейнеры - штука непостоянная. Нужен autodiscovery, чтобы следить за новыми контейнерами. Нужно мониторить сами сервисы - следить за доступностью сервиса, а не конкретного контейнера. 

Чтобы успешно управлять контейнерной инфраструктурой - надо много дополнительных сущностей:
  - Nomad
  - Docker Swarm
  - Kubernetes
  - мониторинг
  - логирование


# Ansible

Плюсы:
  - не нужен агент
  - работа по SSH
  - не нужно программировать - вся настройка в YAML
  - идемпонентность - описывается состояние в которое должна быть приведена система и в идеале данное состояние должно быть идентичным для разных запусков в разное время для системы.
  - нужен только Python

Минусы:
  - нет агента - задачи загружаются по одной и в том порядке что указал создатель плейбука
  - нужен Python
  - YAML - нельзя делать сложную логику и надо следить за пробелами и отступами

Shell-скриптами можно заменить какие-то простые задачи, но в конечном итоге можно увлечься и написать свой Ansible, в котором будут проблемы:
  - время на изобретение велосипеда
  - затраты сотрудников на изучение этого велосипеда

Установить можно через pip (pip install ansible)

`ansible -m setup <host>` - сбор фактов с сервера

`ansible -m ping -i red all -u bond -k`
  - -m - модуль
  - -i - инвентори
  - all - все хосты во всех группах в инвентори
  - -u - пользователь
  - -k - запросить пароль

## Сущности Ansible

Playbook
ключи:
  - --diff - показать какие изменения сделал таск (что было и что стало)
  - --force-handlers - выполнять хендлеры независимо от того, завершился сценарий успешно или неуспешно. По умолчанию сценарий останавливается на ошибке.
  - --inventory - указатель на инвентарь
  - --limit - выполнять задачи не на всех серверах а на определенных группах или определенных хостах
  - --step - используется редко, пошаговое выполнение тасков
  - --become - сделать sudo от имени пользователя, повышение привилегий, можно написать и в инвентаре, и в таске, и в плейбуке
  - --ask-pass - короткая форма -k, запрос на пароль при подключении по ssh

Inventory

Group

## Ускорение работы

Mitogen - штука на Python, которая ускоряет Ansible в разы.
На целевом сервере запускается подобие агента, таски загружаются в один поток.
Устанавливается либо через pip либо через пакет.
Для использования надо включить его в ansible.cfg. 
Нужно включить его в директиву [defaults]:

strategy_plugins = /.../ansible_mitogen/plugins/strategy

strategy = mitogen_linear

Стратегии - linear по умолчанию (все хосты выполняют одну задачу в n потоков=n хостов одновременно), serial - пакетное выполнение на пачке хостов, free - выполнять так быстро как только можно.

## Сущности

Task
  - вызов модуля Ansible. Более 500 модулей, но в основном используется штук 10

Variables
  - позволяют писать универсальные роли

Template
  - на языке Jinja2
  - позволяют создавать файлы на разных типах серверов

Handler
  - таски в самом конце, обычно рестарт сервиса

Role
  - объединение по логическому принципу таски, переменные, темплейты и хендлеры.



# Kubernetes

## Тема №1: Знакомство с Kubernetes, основные компоненты



## Тема №2: Устройство кластера, основные компоненты, отказоустойчивость, сеть k8s



## Тема №3: Kubespray, тюнинг и настройка кластера Kubernetes



## Тема №4: Продвинутые абстракции Kubernetes



## Тема №5: DNS в кластере. Публикация сервисов и приложений



## Тема №6: Работа с Helm



## Тема №7: Ceph, установка в режиме делай как я. Работа с постоянными томами, sc, pvc, pv, подключение томов к подам. Разбор на примере Ceph



## Тема №8: Установка cert-manager



## Тема №9: Обслуживание кластера



## Тема №10: Практическая работа, докеризация приложения и запуск в кластере

