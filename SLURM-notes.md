# SLURM - заметки

# Docker

Хорошая практика - запускать процессы внутри контейнера в foreground (при этом сам запущенный контейнер может работать и в background)
Слои в образе - readonly
.dockerignore - указывать директории, которые не надо класть в образ
Отключение кэшей - для пакетных менеджеров и для сборщиков типа pip
Например для APT внутри директивы установки пакетов - добавить

`RUN apt-get update && apt-get install ... && rm -rf /var/lib/apt/lists/*`

Концепция контейнеров не предполагает заходить внутрь контейнера для сбора и прочтения логов - логи пишутся в stdout/stderr
Все что контейнер написал в stdout/stderr - docker переведет в JSON, добавит метаинформацию и сложит на хосте в определенную директорию
Для того чтобы ловить логи nginx из стандартных файлов куда он их складывает - можно добавить директиву

`RUN set -ex && \
	ln -sf /dev/stdout /var/log/nginx/access.log && \
	ln -sf /dev/stderr /var/log/nginx/error.log`

`set -ex` - это чтобы видеть, какие команды в какой момент выполняются

Разница между `COPY` и `ADD` - `ADD` может скопировать файлы из удаленного источника, разархивировать архив и так далее. Если надо просто скопировать файл с хоста в контейнер - проще использовать COPY.

Разница между `ENTRYPOINT` и `CMD` - последняя чаще всего используется так же как ENTRYPOINT, но есть нюансы

`ENTRYPOINT` - должен использоваться при старте контейнера

`CMD` - добавлять параметры для энтрипойнта

То есть запуск приложения - через `ENTRYPOINT`, а ключи для запуска передать в `CMD`

Docker не про контейнеры. Docker про стандартизацию поставки и распространению ПО.
Воспроизводимость, консистентность.

Docker engine - это демон

Запущен как обычный процесс

`docker build, ps, run` - консольные утилиты, передают GRPC-команды на докер-демон

На том же хосте утилита обращается в UNIX-сокет локальной машины

Docker registry - хранилище images


## Namespace Isolation

Namespace - механизм изоляции процессов друг от друга, вшит в ядро Linux - PID, Net, Mount, User
  - `PID NS` - пространство имен айди процессов. PID 1 - это корневой процесс, без него работа системы завершается. Если скрипт внутри контейнера конечный - контейнер завершается (по умолчанию запуск под PID 1).
  - `NET NS` - сетевое окружение: сетевые интерфейсы (+lo), route tables, iptables, sockets
  - в один NS можно добавлять несколько процессов (например несколько контейнеров объединить общим localhost через который контейнеры могут общаться)
  - `MNT NS` - своя root fs, свои приватные маунты
  - правила сетевого NS можно тюнить в части параметров sysctl для каждого контейнера отдельно
  - `USER NS` - позволяет мапить GID/UID с хоста

Докер это в первую очередь система упаковки и доставки, а не обеспечения безопасности и защиты контейнеров.

Докер не обеспечивает суперизоляцию процессов и их безопасность, это скорее про ВМ или физику.

CGroups - механизм изоляции вычислительных ресурсов процессов друг от друга - CPU, Memory, I/O, Net
  - добавляют overhead - или нет. В зависимости от ситуации

Copy-On-Write - тоже механика ядра Linux. При чтении используется общая копия, при записи - новая копия. Используется также в LXC


## Storage-драйверы

  - самые популярные - **overlay**, **devicemapper**, **AUFS**
  - **devicemapper** - в CentOS дефолтный до недавнего времени, работает через loopback, надо использовать в версии с SYN-пулами. 
  - **overlay** - хорошая поддержка лишь в ядре 4.X. Поддерживается в ядре от 3.10 - CentOS 7.4. Для 7.4 рекомендуется overlay2.
  - для Ubuntu и Debian - лучший драйвер это **AUFS**.
  - **BTRFS/ZFS** - первый не развивается, второй под Linux практически тоже. 


## Log-драйверы.

  - по умолчанию - JSON-файл, со своей задачей справляется.
  - journald - из системного журнала. Нужно тюнить, лимиты по умолчанию на прием логов скромные. Плюс к тому есть хард-лимиты - выше определенных значений его не затюнить и поэтому лучше его не использовать.
  - syslog - по UDP/TCP/TLS
  - fluentd - по TCP, можно собирать логи из всех источников одновременно
  - ETW -> Windows Event Store
  - Splunk
  - Geif
  - Logentries
  - Amazon CloudWatch
  - Google Cloud
  - из драйвера логи попадают в log shipper.
  - рекомендуется для Docker остаться на JSON-файле (не теряя возможности выполнять docker logs), собирать логи через fluentd, потом в ElasticSearch + Kibana для просмотра.

Полезные опции
  - `dockerd --default-ulimit` - аналог docker run -ulimit, переопределяет максимальное число процессов, которые может запускать контейнер.
  - `--dns` - переопределять DNS-серверы
  - `--insecure-registry` - если свой реестр без сертификата, по умолчанию docker не даст подключиться к реестру без TLS.


## Docker Compose

Это обертка на Python над Docker - позволяет по описанию в YAML запускать многоконтейнерную структуру.

В 3 версии файла (версия декларируется параметром version: в YAML) выпилили поддержку healthcheck-ов и зависимостей.

```yaml
healthcheck:
  test: ["CMD", "команда", "параметры"]
  interval: 1s
  timeout: 1s
  retries: 60
```

`Healthcheck` - это команда, которая должна возвращать нулевой exit-код. Если не возвращает - повторяется с нужным интервалом, после нужного таймаута и нужное количество раз.

`docker-compose.override.yml` - применяется автоматически при `docker-compose up` без указания дополнительных файлов.
Как пример - можно описать пробрасываемые порты и подключаемые тома с локального хоста при локальной разработке.
docker-compose.test.yml - нужно руками указывать `docker-compose up -f <файл>`. Оверрайд при этом отключается.
Как пример - использование переменных для тестового окружения.


## Docker registry

Альтернативные продукты - Harbor
  - хранение образов
  - авторизация
  - ротация
  - сканирование 
  - hook API
  - хранение других сущностей

Можно указать альтернативный registry в docker run, по умолчанию образы берутся с hub.docker.io


## Лучшие практики, паттерны и антипаттерны

Файлы, где описаны зависимости - копируются в начале

Логично что после копирования файлов - надо делать установку зависимостей, а потом копировать сам код.

Если копировать скрипты например из Debian на Alpine - то надо следить как именуются пользователи. В Debian nginx запускается под пользователем `www-data`, в Alpine - под `nginx`.

Добавляя пользователя внутрь контейнера - усложняется процесс сборки, если можно без этого обойтись - то надо обходиться.

Update делать нормально, upgrade - нет, так как это плохое, непредсказуемое поведение. При каждой сборке образа будет апгрейд пакетов, и что-то может поломаться.

Dev-пакеты для того чтобы собрать зависимости - лучше не делать в образе, в котором будет запускаться приложение. Лучше их собирать в новый базовый образ.

Надо отключать кэши и не тащить в образ.

Пакеты надо ставить до добавления кода, если так не делать - любое изменение кода будет вызывать повторную выкачку и установку пакетов.

Бандлы пакетов лучше выносить в переменные и указывать в начале Dockerfile, чтобы можно было потом легко вносить изменения:

`ARG BUILD_PACKAGES="nginx nodejs dcron tzdata postgresql-dev libxslt-dev"`

Статику можно собирать либо в Dockerfile, либо в `ENTRYPOINT`.

Лучше в Dockerfile, так как контейнеры могут падать, рестартоваться, а смысл контейнеров - как можно быстрее поднять работающее приложение.

В идеале **1 контейнер = 1 процесс.** В реальной жизни часто приходится искать компромиссы. 

Приложения надо адаптировать. Если приложение не писалось под Docker - есть ненулевая вероятность, что оно не будет нормально работать. Пример - **Java 7**, которая не могла правильно определять количество процессоров внутри контейнера.

Архитектуру надо прорабатывать - как с точки зрения инфраструктуры, так и с точки зрения приложений и взаимодействия между ними. Как пример - делить приложение на фронт и бэк с общением между ними по HTTP.

Docker надо мониторить, причем не так как сервера. Контейнеры - штука непостоянная. Нужен **autodiscovery**, чтобы следить за новыми контейнерами. Нужно мониторить сами сервисы - следить за доступностью сервиса, а не конкретного контейнера. 

Чтобы успешно управлять контейнерной инфраструктурой - надо много дополнительных сущностей:
  - Nomad
  - Docker Swarm
  - Kubernetes
  - мониторинг
  - логирование


# Ansible

Плюсы:
  - не нужен агент
  - работа по SSH
  - не нужно программировать - вся настройка в YAML
  - **идемпонентность** - описывается состояние в которое должна быть приведена система и в идеале данное состояние должно быть идентичным для разных запусков в разное время для системы.
  - нужен только Python

Минусы:
  - нет агента - задачи загружаются по одной и в том порядке что указал создатель плейбука
  - нужен Python
  - YAML - нельзя делать сложную логику и надо следить за пробелами и отступами

Shell-скриптами можно заменить какие-то простые задачи, но в конечном итоге можно увлечься и написать свой Ansible, в котором будут проблемы:
  - время на изобретение велосипеда
  - затраты сотрудников на изучение этого велосипеда

Установить можно через pip (pip install ansible)

`ansible -m setup <host>` - сбор фактов с сервера

`ansible -m ping -i red all -u bond -k`
  - -m - модуль
  - -i - инвентори
  - all - все хосты во всех группах в инвентори
  - -u - пользователь
  - -k - запросить пароль


## Сущности Ansible

### Playbook

ключи:

  - `--diff` - показать какие изменения сделал таск (что было и что стало)
  - `--force-handlers` - выполнять хендлеры независимо от того, завершился сценарий успешно или неуспешно. По умолчанию сценарий останавливается на ошибке.
  - --inventory - указатель на инвентарь
  - `--limit` - выполнять задачи не на всех серверах а на определенных группах или определенных хостах
  - `--step` - используется редко, пошаговое выполнение тасков
  - `--become` - сделать sudo от имени пользователя, повышение привилегий, можно написать и в инвентаре, и в таске, и в плейбуке
  - `--ask-pass` - короткая форма -k, запрос на пароль при подключении по ssh

### Inventory

### Group


## Ускорение работы

**Mitogen** - штука на Python, которая ускоряет Ansible в разы.  
На целевом сервере запускается подобие агента, таски загружаются в один поток.  
Устанавливается либо через pip либо через пакет.  
Для использования надо включить его в ansible.cfg.   
Нужно включить его в директиву [defaults]:  

```
strategy_plugins = /.../ansible_mitogen/plugins/strategy

strategy = mitogen_linear
```

Стратегии - **linear** по умолчанию (все хосты выполняют одну задачу в n потоков=n хостов одновременно), serial - пакетное выполнение на пачке хостов, free - выполнять так быстро как только можно.


## Сущности

### Task

  - вызов модуля Ansible. Более 500 модулей, но в основном используется штук 10

### Variables

  - позволяют писать универсальные роли

### Template

  - на языке Jinja2
  - позволяют создавать файлы на разных типах серверов

### Handler

  - таски в самом конце, обычно рестарт сервиса
  - вызываются по условию, описываемому в директиве `when: `

### Role

  - объединение по логическому принципу таски, переменные, темплейты и хендлеры.


## Переменные

Могут устанавливаться в нескольких местах и имеют разный приоритет.  
Приоритет с самого низкого:

  - в роли в каталоге `role/defaults` - переменные по умолчанию
  - в инвентаре в переменных группы `inventory/group_vars` - в файле с указанием хостов
  - просто в инвентаре 
  - в инвентаре в каталоге `inventory/host vars` - применяются к каждому хосту в отдельности
  - в самом плейбуке в разделе `vars (play vars)`
  - экстра переменные, задаваемые через ключ -e - это высший приоритет

Более полный приоритет из официальной документации:
  1 command line values (eg “-u user”)  
  2 role defaults [1]  
  3 inventory file or script group vars [2]  
  4 inventory group_vars/all [3]  
  5 playbook group_vars/all [3]  
  6 inventory group_vars/* [3]  
  7 playbook group_vars/* [3]  
  8 inventory file or script host vars [2]  
  9 inventory host_vars/* [3]  
  10 playbook host_vars/* [3]  
  11 host facts / cached set_facts [4]  
  12 play vars  
  13 play vars_prompt  
  14 play vars_files  
  15 role vars (defined in role/vars/main.yml)  
  16 block vars (only for tasks in block)  
  17 task vars (only for the task)  
  18 include_vars  
  19 set_facts / registered vars  
  20 role (and include_role) params  
  21 include params  
  22 extra vars (always win precedence)  


## Модули

yum repository: устанавливает репо для yum
yum: установка пакетов
template: как правило используется для настройки конфигов тех или иных серверов
service: запускает сервис
file: удалить файл (state: absent) или создать каталог (state: directory)
include task: "имя таска из отдельного файла" - добавить задачу на выполнение

Если указать внутри модуля systemd daemon_reload: yes - то это перезагружает модуль.

Внутри темплейтов:

{% %} - операторы Jinja2
{{ }} - переменные Jinja2
register - запоминает состояние таска. Создается переменная и в нее записывается, что таск сделал и что изменил. Эту переменную можно проверить в следующих тасках. Можно проверить например так:

when:
  - <переменная>.changed

В каталоге host_vars файл с именем хоста содержит все переменные, которые будут применяться к данному хосту

В каталоге group_vars:
  - папка all - все сервера в инвентаре. Все переменные во всех файлах в папке будут применены ко всем хостам.
  - файл с именем группы - содержит переменные, действующие на группу.



## Инвентарь

[группа хостов]
Внутри группы - хосты + переменные
ansible_host=IP //если не прописали DNS или если DNS не работает

Если в качестве инвентаря задать каталог - то исполняемые файлы будут рассматриваться как динамические источники для инвентаря, а остальные - как статические источники.
Файлы со следующими расширениями будут игнорироваться:
  - ~, .orig, .bak, .ini, .cfg, .retry, .pyc, .pyo

Можно задать переменную inventory_ignore_extensions в ansible.cfg чтобы переопределить список игноров.

В каталогах host_vars и group_vars переменные могут быть в формате yaml и json, либо без расширения.


## Настройка Ansible

1) Переменные окружения (`ANSIBLE_CONFIG`)   
2) `ansible.cfg` в текущем каталоге  
3) `~/.ansible.cfg`  
4) `/etc/ansible/ansible.cfg`  

Именно в этом порядке переменные и будут проверяться.

`become = true` // выполнять таск с повышенными привилегиями  
`become_user = root` // под каким юзером повышать привилегии  
`forks = 100` // сколько одновременных потоков. Чем больше форков - тем больше памяти требуется. 300-400 форков съедят больше 30 гигов памяти.  
`roles_path = ...` // в каком каталоге смотреть роли  
`log_path = ...` // в какой каталог писать логи  
`host_key_checking = false` // аутентификация по ключу  
`retry_files_enabled = true` // если запускать плейбук несколько раз - брать информацию о выполненных задачах и состоянии хостов из retry-файлов  
`stdout_callback = debug` // выводить в stdout расширенную инфо  


# Kubernetes (Slurm Base)

## Тема №1: Знакомство с Kubernetes, основные компоненты

Новая версия K8S - 1.18. Юбилейный интенсив и первый, который выходит по этой версии.

99% инсталляций - на базе Docker.

Docker - как фура.  
Docker Compose - как товарный поезд.

  - нет масштабирования
  - привязан к хосту
Kubernetes - грузовой порт.
  - логистика==оркестрация
  - учет
  - оптимизация хранения
  - отправка==scheduling

Оркестратор - основная функция K8S.  

### Почему K8S?

  - вырос из Google. Google==хайп и бренд.
  - удачные архитектурные решения
  - большое коммьюнити - большое количество учебных материалов, статей, мануалов, паттерны-антипаттерны, курсы итд. Чем больше инженеров, которые пишут код - тем больше векторов развития. Поиск оптимального пути и оптимальных решений развития продукта.
  - есть интеграция с экосистемой AD и Microsoft. На Windows Server 2019 работает с Flannel.

### Когда нужен?

  - immutable - неизменяемость. Как контейнеры, так и ноды кластера будут работать одинаково на всех средах, где установлен Docker. K8S - несколько бинарников, не требующих внешних зависимостей и все остальные компоненты в контейнерах. 
  - декларативность. Описание в YAML, это обычные текстовые файлы -> используются обычные инструменты разработки типа GIT, версионирование, unit-тесты итд. Ложится на концепцию IaC.
  - Self-Healing - каждый компонент отвечает за свою часть инфраструктуры и поддерживает его в актуальном состоянии. Если что-то случится с контейнерами - оркестратор разберется )
  - большая распределенность и независимость компонентов кластера и приложений (Decoupling), компоненты инфраструктуры полагаются на свои SLA.

### Когда не нужен?

  - K8S ради зарплаты - инженеры работающие с Docker на небольших средах - усложняют проект, часто не получая профита.
  - маленькая инфраструктура где нет горизонтального масштабирования.
  - слышали про "стандарт отрасли" - появилось желание "положить всё в Кубернетес"
  - желание получить кнопку "сделать хорошо" без налаженных процессов автоматизации, тестирования, разработки итд

### Архитектура

  - основной элемент - **KubeAPI** сервер. Через него идет доступ в кластер плюс через него общаются компоненты кластера.
    - UI - дашборд встроенный + сторонние дашборды. В основном для разработчиков. Удобно что может генерировать ссылки на объекты. 
    - CLI - kubectl. В основном для инженеров. 
  - Kubernetes Master - это набор из нескольких компонентов, каждый из которых делает свои задачи. Бинарные файлы, которые реализуют логику работы кластера
  - Worker Node - сервера, на которых запускаются приложения.
  - **ETCD** - в качестве хранилища конфигурации. 
  - никакой компонент напрямую не общается друг с другом, всё через Kube API
  - никакой компонент не говорит другому, что нужно делать, всё декларативно через манифесты
  - компоненты независимы и отвязаны друг от друга

### Базовые абстракции

**POD** - один или группа контейнеров, объединенных в логическую единицу. Кубернетес не оперирует отдельными контейнерами.  

- Контейнеры в поде в одном общем сетевом namespace, PID namespace.  
- Под - минимум 2 контейнера - контейнер с приложением + технический контейнер (с процессом pause, он всегда спит и берет на себя все namespace). Если контейнер внутри пода должен быть перезапущен, то перезапущенный контейнер поднялся бы в другом неймспейсе, так как есть технический контейнер, который держит неймспейсы, то новый контейнер запускается в том же неймспейсе. Средствами K8S - его не видно, видно через Docker, CRI-O итд.  
   - POD - минимальная единица, которой может оперировать K8S  
   - все контейнеры пода работают на одном физическом хосте  

Когда контейнеры надо объединять в одном POD?  

   - когда должны быть на одном хосте  

- когда масштабируются линейно  

- если компоненты этих контейнеров имеют сильную связь, один без другого не живет без локальной связи и ломаются если связь по сети.  

- обязательные поля в манифесте - `spec:containers:name`    

  

**REPLICA SET** - запускает несколько копий пода. Задача - скейлить поды. Кол-во подов считается по заданию лейблов на подах. Лейбл это key-value пара.  

- Под в репликасете описывается в поле `spec:template`. Есть `metadata:labels`. Поле name отсутствует в template, оно будет заполняться автоматически.  
- Если выставить отдельному поду такой же лейбл, как в репликасете - то репликасет победит и под будет уничтожен.  
- Если изменить RS - то это автоматически не приведет к пересозданию подов. Работающие поды так и будут работать на старой версии. Обновить можно либо создав новый под заскейлив RS, либо удалив работающий под.  



**DEPLOYMENT** - самая распространенная абстракция в продакшне.  

- есть поле spec:strategy. Дефолтная стратегия - RollingUpdate (обновлять реплики по одной). Recreate - убить все реплики разом и поднять новую версию.  
- `RollingUpdate:MaxSurge/MaxUnavailable` - можно задавать в штуках, можно в процентах.  
- деплоймент каскадно создает RS.  
- обновление деплоймента обновляет приложение налету, в отличие от RS!  
- обновление деплоймента создает новый RS с новыми настройками. Старый остается жить для возможности отката обновления.  
- `kubectl rollout undo deployment <depl name> --to-revision=...` - для отката обновлений. Работает только с деплойментами!  

**Пробы**

  - **Liveness Probe** - контроль за состоянием приложения во время жизни, работает постоянно. Работает уже после того, как приложение поднялось. Если проба не прошла - приложение перезапустится.
  - **Readiness Probe** - принимает, готово ли приложение принимать трафик, если нет - приложение выключается из балансировки, работает постоянно. Проба прошла = под переходит в Ready.
    В жизни большинство приложений имеют одинаковые Liveness и Readiness пробы.
  - **Startup Probe** - появилось недавно. Для того, чтобы проверять legacy-приложение или приложения, которые долго стартуют, типа Java. Можно самостоятельно указывать, как проверять, запустилось ли приложение. 
    `failureThreshold`: количество последовательных неудач в пробе, чтобы она считалась неудачной. Сбросит счетчик успешных проб.  
    `successThreshold`: количество последовательных успехов в пробе, чтобы она считалась удачной. Сбросит счетчик неуспешных проб.  
    `periodSeconds`: с какой частотой будет происходить проверка.  
    `httpGet`: успешными считаются 200-300е коды ответа.  

Один из подходов к limit management - запустить приложение без реквестов и лимитов и посмотреть сколько оно будет есть в максимуме. Второй подход, более правильный - это НТ.  
Некорректно выставленные лимиты и реквесты - это лучше, если не выставленные вообще.   
У системных компонентов K8S - лимиты и реквесты либо не проставлены, либо проставлено только одно.   

**Ресурсы**

  - **Limits** - верхняя граница ресурсов, которые под может использовать на ноде
  - **Requests** - кол-во ресурсов, которые резервируются для пода на ноде, НЕ делятся с другими подами.
  - основные ресурсы: CPU, RAM
  - градация выделения CPU - миллиядро (millicore). Это time-based multiplexing, речь про выделение процессорного времени одного логического ядра ноды.
  - QoS Class - проставляется автоматически в зависимости от реквестов и лимитов. Есть **Burstable**, есть **Guaranteed**, есть **Best Effort**. Последний включается если реквестов и лимитов не задано. Если реквесты равны лимитам - то выставляется Guaranteed. Guaranteed в K8S считаются наиболее важными и критичными приложениями (так как 100% резерв ресурсов)
    Если QoS Class: Guaranteed - то у него будет очень высокий OOM Score - значит K8S будет до последнего стараться не убивать этот под при просадке кластера по памяти.

### Настройка приложения.

Для stage и prod как правило нужны разные настройки приложения.

**ConfigMap** - YAML-файл с секцией data, в которой настройки в формате key:value
Монтирование - через VolumeMounts.

  - volumeMounts - на уровне контейнера
  - volumes - на уровне пода

**Secrets** - хранение в base64 некоторой чувствительной информации.

  - `generic` - пароли/токены для приложений
  - `docker-registry` - авторизация в реджистри
  - `tls` - сертификаты для Ingress

Секреты нужны только для того, чтобы отделить информацию, которую нельзя хранить в ConfigMap. Особенно важно для RBAC - кому в принципе можно смотреть в секреты, кому нет. 

Для всех секретов кроме generic - есть жестко заданные названия полей.

Кодировка в Base64 - не только для безопасности, но и для того, чтобы <u>спецсимволы в паролях не сломали YAML.</u>

Ссылаться на секреты можно в описании переменных окружения: `spec:containers:env`

```yaml
name: <NAME>
valueFrom:
  secretKeyRef:
    name: <secretName>
    key: <значение в секрете>
```

**Service** - это абстракция, которая позволяет обращаться к любому однотипному поду за ним. <u>По сути - это логический балансировщик.</u> 

  - сопоставление объектов как и в деплойментах - по лейблам (меткам)
  - в сервисе указывается `selector:<набор лейблов>`
  - у сервиса есть раздел `ports` - это набор портов, которые обслуживает сервис. -`port` - порт, на котором принимается трафик. `targetPort` - порт, открытый на поде, куда надо слать трафик. 
  - `ClusterIP` - поле, которое добавляется кластером K8S, срабатывает Service Discovery и присваивается динамический IP-адрес, который добавляется в манифест сервиса в это поле.
  - работает через IPTables и NAT

**Endpoints** - абстракция, которая создается автоматически при создании сервиса. Это список IP-адресов, на которые надо балансировать запросы при обращении к сервису.  
Если `ReadinessProbe` не проходит, то под удаляется из перечня эндпойнтов. Но не мгновенно. 

**Ingress** - работает на L7. Работает только при наличии в кластере Ingress Controller-а. 

  - самый популярный - на базе nginx (community)
  - есть еще авторский от самой компании Nginx
  - есть Envoy, Traefik, HAProxy и облачные разные варианты.
  - сущность, которая описывает правила маршрутизации HTTP-запросов. 
  - описываем "что пришло - куда послать"
  - ингресс принимает запрос и отправляет его на сервис

С версии 1.18 класс IngressController-ов можно указывать в манифесте.

**PV/PVC**

  - PV описывает информацию по конкретному тому
  - PVC - требования на подключения к тому
  - указывается `StorageCLass`, если не указывается то подключается та СХД что по умолчанию
  - <u>Claim это прокси между PV и подом</u>.
  - Если закончились PV в кластере, то под не запустится
  - `provisioner` - специальное ПО, которое умеет ходить в СХД, создавать диски и делать из них PV. Использование provisioner-а позволяет откусывать ровно столько места от СХД, сколько нужно поду.
  - `ReadWriteOnce` - эксклюзивный доступ на запись. Подмонтирован может быть только к одному узлу.
  - `ReadWriteMany` - множественный доступ на запись, блокировки разруливаются на уровне самой СХД

**initContainers** - специальные контейнеры, которые запускаются перед приложением. Например - чтобы поправить права на доступ к томам, чтобы смигрировать БД, доп. настройки (куда-то сходить, что-то дёрнуть и так далее)


### Полезные команды

`kubectl create` - создает новые объекты

`kubectl apply` - работает так же как create если объекта нет, если есть - обновляет.

`kubectl describe` - универсальная команда диагностики. Если что-то не так - смотрим Events.

`kubectl get po --show-labels` //показать лейблы подов

`export EDITOR=vim` //задает редактор по умолчанию для `kubectl edit`



## Тема №2: Устройство кластера, основные компоненты, отказоустойчивость, сеть k8s

CoreDNS - сервис, отвечающий за Service Discovery

### Компоненты кластера

  - **ETCD**
    - key-value хранилище обо всей информации о кластере
    - порт 2379 для подключения клиентов и 2380 для взаимодействия между нодами
    - 2 версии API - v2/v3. 
    - <u>строго требует быстрых дисков</u>.
  - **API Server**
    - центральный компонент K8S
    - <u>единственный, кто может общаться и писать в ETCD напрямую</u>
    - обычный REST API, поддерживает HTTP запросы
    - аутентификация и авторизация
  - **Controller Manager**
    - набор контроллеров
    - Node Controller - управление нодами
    - Replicaset Controller
    - Endpoints Controller - создает эндпойнты для сервисов
    - Garbage Collector - сборщик мусора
    - другие...
    - всегда смотрит в API Server и мониторит создания новых объектов. (watch - подписка на события)
  - **Scheduler**
    - назначает запуск POD на ноды, учитывая:
      - QoS
      - affinity/anti-affinity
      - Priority Class (DEV/Prod)
      - выделяет ресурсы
    - отслеживает (watch) создание новых подов в API Server. Назначает **NodeName** для новых подов и обновляет манифест.
  - **Kubelet**
    - работает на всех серверах кластера
    - node agent
    - работает не внутри контейнера
    - systemd приложение на хосте
    - отдает команду docker daemon-у
    - фактически создает поды
  - **Kube-Proxy**
    - смотрит в Kube-API
    - стоит на всех хостах
    - управляет сетевыми правилами на нодах
    - реализует правила (IPtables - олдскул, IPVS - стильно модно молодежно)
  - **контейнеризация**
  - **сеть**
  - **DNS**
   - для каждого сервиса создается имя `myservice.mynamespace.svc.cluster.local`
   - DNS в кластере работает так же через Service

<u>Service это не прокси!</u>

В Service определяются правила iptables для роутинга

Проблемы NAT в Linux - может быть такое, что отправленные разные пакеты записались с одинаковым исходящим портом в таблицу, обратный пакет пришедший позже - будет отброшен. 

Поэтому появился IPVS. 

**Network**

  - задача сетевого плагина - связать все поды и все ноды друг с другом
  - все сетевые плагины раздают IP адреса подам
  - Flannel в режиме Host Gateway раздает маршруты
      - работает только там где сервера связаны друг с другом по L2
  - Network Policy - этим подам ходить туда, а этим подам туда нельзя (умеет Calico)
  - если IP адреса у вас кончились и у вас Flannel - то все плохо и надо расширять хостовую сеть. Если Calico - то есть возможность добавить дополнительные диапазоны. 
  - лучше побольше нод, поменьше подов на ноду
  - плагины реализуют шифрование между нодами

**Ingress**

  - это абстракция, как внешний трафик будет попадать и распределяться на поды приложения
  - это манифест, в котором описывается куда трафик приходит и куда попадает
  - в стандартном ингрессе на базе nginx внутри конфига будут proxy_pass-ы на апстримы в виде сервисов
  - по факту там не nginx а nginx+openresty, так как мягкий релоад конфига только в nginx plus
  - есть второй фоновый процесс, который занимается релоадом конфига

**Отказоустойчивый сетап Control Plane**

  - ETCD - 3 штуки минимум, быстрые диски, быстрая сеть
  - API Server - по кол-ву ETCD, чтобы отправлял данные быстро в локальную копию ETCD
  - Controller Manager - только один инстанс работает в момент времени. 
  - Scheduler - только один инстанс работает в момент времени. 
  - Kubelet и Kube-proxy - работают с одним API-сервером. Перед ними на каждой ноде запускают контейнер с Nginx, на котором делают proxy_pass на upstream группы API Server-ов. 


## Тема №3: Kubespray, тюнинг и настройка кластера Kubernetes

Развертывание кластера через Kubespray
  - Rancher хорошо, но часто ломается
  - kubeadm хорошо, от авторов K8S, но требует много ручного труда
  - kubespray ставит отказоустойчивый кластер одной кнопкой
  - kubespray раньше ставил и управлял пакетами, сейчас половина кубеспрея это вызов kubeadm с разными ключами
  - нет возможности апгрейда кластера, развернутого по классике - серты выписываются на 1 год, обновлять вручную (сертов выпускается много). Сейчас функционал допилен, серты обновляются одной командой. Также серты обновляются при процедуре обновления кластера.
  - если установка вылетела по ошибке - повторный запуск может не помочь
  - подготовка серверов:
    - kernel 4.x
    - disable firewall
    - local net
    - disable swap
    - master - 2CPU, 4GB RAM
    - Ingress - 1CPU, 2GB RAM
    - Node - 4CPU, 8GB RAM
  - etcd можно ставить не только на мастерах, но и на выделенных нодах
  - опция `download_run_once: true` //скачивание один раз и потом распространение локально по узлам кластера
  - опция `etcd_memory_limit: 0` //раньше при превышении потребления памяти в 512МБ контейнеры падали. Лучше пусть он съест всю память на хосте, чем упадет.
  - используется все-таки IPTables

    

## Тема №4: Продвинутые абстракции Kubernetes


### DaemonSet

Задача на примере мониторинга:
  - на каждой ноде автоматически запускается агент
  - управляются агенты из одной точки
  - конфигурируются из одной точки

Варианты решения:
  - **Static Pod** - был придуман для решения проблемы курицы и яйца. Когда рождается первый kubelet, он обращается к API Server, чтобы узнать, что надо запускать. Но API Server-а еще нет в природе. Для этого придумали костыль Static Pod, kubelet идет в специальный каталог с манифестами подов, и запускает их у себя на узле. Это манифесты для запуска системных компонентов кластера - ETCD, kube-proxy, nginx-proxy, API Server, итд. 
    Есть проблемы с управлением и конфигурированием - нельзя удалить, нельзя поменять настройки из одного места - надо идти на узел и менять настройки в файлах на каждом узле.   
  - **Pod Anti-Affinity** - как рассказать планировщику (scheduler) чтобы не запускать несколько копий на одном и том же узле. Проблемы с ситуацией, когда добавляются узлы в кластер. Надо сходить в деплоймент и вручную увеличить количество реплик по числу узлов.
  - **Daemon Set** - нет поля Replicas - под в составе демонсета работает на каждом узле кластера. 

Используется для всех системных задач, где нужно обеспечить работу на каждом узле кластера:
  - кэширующий DNS
  - сетевые плагины
  - аудит
  - storage plugin
  - ...

Как работает:
  - запускает поды на всех нодах кластера
  - описание соответствует Deployment
  - при добавлении ноды добавляет под
  - при удалении ноды GC удаляет под

**Taint** и **Tolerations** - механизм регулирования, на каких нодах можно запускать конкретные деплойменты, на каких нельзя.

Как игнорировать Taints на узлах

```yaml
effect: NoSchedule
operator: Exists
```

NoSchedule - только на запуск новых подов.

Toleration - это снятие запрета для конкретного Taint на ноде.

'-' (минус) в конце команды - снятие/удаление объекта. Пример для Taint:

`kubectl taint nodes foo dedicated:NoSchedule-`



### StatefulSet

Позволяет запускать группу подов (как Deployment)
Поды, которые хранят свое состояние
  - гарантирует их уникальность
  - гарантирует их последовательность

**PVC Template**

  - при удалении не удаляет PVC

Используется для stateful-приложений:
  - Rabbit
  - DB
  - Redis
  - Kafka
  - ...

При создании SS для каждого пода генерируется собственный PVC.
Название пода - имя SS и индекс (с нуля)

**LocalVolume** - это альтернатива небезопасному HostPath.

В **HostPath** можно было к примеру, утащить корень узла, со всеми сертификатами.

**Affinity**

  - `nodeAffinity` - позволяет задавать условия запуска пода на узлах
  - `requiredDuringSchedulingIgnoredDuringExecution` - для жесткого шедулинга пода на узлах
  - `preferredDuringSchedulingIgnoredDuringExecution` - для мягкого шедулинга (постараюсь запустить на нужной ноде, ну а там как пойдёт)
  - `topologyKey` - ключ, который должен быть разный на всех подах. Обычно - имя узла (`kubernetes.io/hostname`)

Удаление StatefulSet - по одному, в обратном порядке от создания.
PVC делать на NFS - очень рискованно.

  - проблемы с диспетчеризацией и блокировками
  - работает нормально только на pNFS + Trident через StorageClass (NetApp)
  - может довести клиентов до kernel panic
  - поднимает в потолок iowait

### Job/CronJob

**Job** - для тех задач, которые надо выполнить один раз без периодичности. Например - миграция БД.

  - создает под для выполнения задачи
  - перезапускает поды до успешного выполнения задачи
  - или до истечения таймаутов: activeDeadLineSeconds (лимит на время работы всего Job, неважно сколько подов и сколько раз под запускался и падал) или backoffLimit (сколько раз Job может падать)

**CronJob** - для задач, которые надо выполнять по расписанию 

  - `startingDeadlineSeconds` - странная штука. Рекомендуется ставить в половину времени запуска. Контроллер считает сколько пропущенных либо незапущенных попыток стартовать задание за значение этого параметра в секундах, если больше чем половина - отменяет задачу и не будет дальше пытаться запустить джобу. 
  - `concurrencyPolicy` - Allow (разрешать одновременный запуск джобов - не рекомендуется), Forbid (запретить), Replace (замещать)
  - `successfulJobsHistoryLimit` - лимит истории удачных джобов
  - `failedJobsHistoryLimit` - лимит истории неудачных джобов
  - создает объект Job примерно в тот момент, когда он должен быть выполнен. Иногда создается 2 экземпляра джобы, либо ни одного. Джобы должны быть идемпотентны - мочь запускаться одновременно, на разных наборах данных и приводить целевой объект к нужному значению.

### Role-based Access Control (RBAC)

**Авторизация**

Любой запрос в API - проходит через ролевую модель. Может конкретный пользователь получить тот или иной доступ к объекту API или нет.

K8S ничего не знает о пользователях, как например AD, LDAP, СУБД. Надо через Oauth модуль подключать сервис аутентификации и локальный объект сопоставить с пользователем. Максимум что можно приравнять к пользователю - это **ServiceAccount**. 

  - `Role` - список объектов (resources в apiGroup) и прав на них (verbs). Область - конкретный Namespace
  - `RoleBinding` - связующее звено между сервис-аккаунтом и ролью - сервис аккаунт такой-то с именем таким-то в Namespace таком-то.
  - `ClusterRole` - то же что и роль, но область - весь кластер. Если указать в RoleBinding кластерную роль, мы берем права на объекты кластерной роли, но только к тем объектам, которые есть в локальном Namespace
  - `ClusterRoleBinding` - то же что и RoleBinding но для кластерных ролей
  - `ServiceAccount` - нужен для запуска сервисов, читай подов. По умолчанию создается на каждый namespace и все поды в данном NS работают под данным сервисаккаунтом. Имеется в виду: внутрь контейнера монтируется токен от сервис-аккаунта. 

Если в HTTP Header указать bearer authorisation и указать в нем токен от сервис аккаунта - можно авторизоваться.

И приложение может слать с этим токеном запросы в Kube API.

По умолчанию в каждом поде добавляется VolumeMount "default-token-...", куда монтируется токен сервис-аккаунта. 

**ApiGroups** - концепция для группировки объектов для назначения прав. Объекты, которые создавались в K8S до того как были придуманы apiGroups - лежат в корневой группе - "".
Пример:

```yaml
rules:
- apiGroups:
  - ""
    resources:
  - namespaces
    verbs:
  - get
- apiGroups:
  - ""
    resources:
  - configmaps
  - pods
  - secrets
  - endpoints
    verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
    resources:
  - services
    verbs:
  - get
  - list
  - update
  - watch`
```

**Resources** - объекты кластера.

**Verbs** - права. 

```
GET /apis/networking.k8s.io/v1beta1/namespaecs/{namespace}/ingresses/{name}

- apiGroups: [...]
  resources: [...]
  verbs: [...]
```

Обычно есть пользователи, и на них навешиваются права. В K8S наоборот - сначала создаются роли и права, а потом мапятся с помощью Binding-ов на пользователей.

Аутентификация по сертификатам: CN берет в качестве `kind:User`, Organization в качестве `kind:Group`

**Техобслуживание узла.**

  - Раньше была опция cordon, узел надо было кордонить (выгонять все поды) перед обслуживанием.
  - теперь на узел вешается Taint:NoSchedule, Taint:NoExecute. Второй Taint видит kubelet и начинает эвиктить поды с узла. Раньше Taint-ы в таком формате были неподдерживаемой опцией.

**Что делать если хочется положить БД в K8S?**

  - без привязки к куберу, я лично пробовал lustre, gpfs, glusterfs, nfs и чуток ceph, но очень давно.
  - больше всего gpfs зашёл, но очень много бабла надо на нормальный сетап
  - gluster тормозит даже в простейшем сетапе аля сделай две ноды с реплицированием
  - minio не катит если много мелких файлов писать, типа картиночки хранить 
  - для бд - локальный nmve, если много денег - emc unity, для его есть нативный провижинер в кубе
  - если немного денег - drbd(piraeus\linstore), но есть сложности в настройке, большая избыточность.


## Тема №5: DNS в кластере. Публикация сервисов и приложений

Первый запрос от пода - в **Local DNS Cache.**

Если нет ответа - запрос идет в **CoreDNS** - основной DNS-сервис в K8S. CoreDNS отдает ответ в кэширующий DNS-сервер и тот отдает ответ поду.

Почему такая схема - потому что в Linux NAT теряются пакеты. Одно из решений - IPVS вместо IPTables, но это плохо. Второй путь - запустить кэширующий DNS-сервер на каждой ноде в виде DaemonSet. Уменьшается поток трафика на основной DNS-сервер, поскольку доступ к нему идет на объект Service, а значит будет работать NAT. 

Запрос в CoreDNS отправляется по TCP, а не по UDP 

DNS-Autoscaler - это специальный под, который будет плодить поды с CoreDNS, в зависимости от размера кластера.

`# cat /etc/resolv.conf` - из пода:

`options ndots:5` - внешний запрос будет резолвиться только если у него от 5 точек в имени.

Настройка CoreDNS kubernetes autopath - чтобы <u>внешние запросы сразу отправлялись на внешний DNS.</u>

```
        kubernetes {
            pods verified
            fallthrough
        }
        autopath @kubernetes
```

Публикация приложений:
  - через Service: L3 OSI, NAT, kube-proxy
  - через Ingress; L7 OSI, HTTP/HTTPS, nginx/envoy/haproxy/traefik

Типы сервисов:
  - **ClusterIP** - балансирует трафик на поды. При создании сервиса создается запись в CoreDNS с именем названия сервиса. Нужно в первую очередь для коммуникации внутри кластера. Можно с локальной машины сделать порт-форвард для проверок: `kubectl port-forward service/my-service 10000:80` 
  - **NodePort** - для доступа снаружи. Открывает порт с большим номером на каждой ноде кластера. 
  - **LoadBalancer** - для доступа снаружи через балансировщик. Заточено под облачные провайдеры, где можно заказать отдельный контроллер доступа. Технически на baremetal можно попробовать сделать такую публикацию через MetalLB. Есть возможность задать конкретный IP для балансера. 
  - **ExternalName** - минималистичный сервис, сопоставляем имени сервиса внешней DNS-записи. Для того чтобы поды обращались к сервису изнутри кластера и попадали на сервис снаружи кластера. 
  - **ExternalIP** - похож на NodePort, но создает правила трансляции для IP-адресов. Обычно это для кейса с VRRP и общим VIP-адресом, этот VIP-адрес вешается на ExternalIP.

**Headless Service (безголовый сервис)**

  - `.spec.clusterIP: None`
  - резолвится в IP всех эндпойнтов
  - создает записи с именами всех эндпойнтов
  - если сделать `nslookup <servicename.default.svc.clustername.local>` - то отдаст стоьлко хостнеймов, сколько подов сидит за сервисом. 

**Ingress Controller**

  - x.y.z (конкретный домен) - на один сервис
  - y.z/w (sub-path) - на другой сервис
  - others - на третий сервис
  - есть специальные аннотации `metadata:annotations:nginx.ingress.kubernetes.io/...` - читать в документации. В аннотациях задается сразу кусок конфига nginx, но то что пишется в аннотациях - не проверяется в Kube API на логику, можно легко сломать ингресс. 
  - В последней версии ингресс контроллера можно добавить через Helm Chart - Validation Webhook, через который можно валидировать конфиг ингресса до применения.
  - по умолчанию ингресс - HTTP. Для того чтобы сделать HTTPS - надо создать секрет с сертификатом и указать сертификат в Ingress в spec:tls:-hosts:-hostname:..
    `kubectl create secret tls ${CERT_NAME} --key ${KEY_FILE} --cert ${CERT_FILE}`  

Впускать трафик внутрь K8S - лучше всего через ingress controller. Отдельный Ingress от Nginx имеет больше возможностей по балансировке по сравнению со встроенным. 

С голым TCP правильно работать через сервисы, на некоторых ингрессах, например Nginx - есть возможность работы с TCP/UDP. 

Мониторинг и масштабирование ингрессов - есть autoscaler для ингрессов, но адекватно работает только с публичными облачными провайдерами. 


## Тема №6: Работа с Helm

Как в принципе деплоить приложения в кластер?
  - последовательно по манифестам - самое простое. Удобно когда мало манифестов и 1-2 приложение
  - темплейтировать приложения:
    Kubectl-based (сгенерить манифесты и отправить в kubectl apply):
    - sed/envsubst
    - ansible - Jinja + подключить плагины для Kubernetes.
    - ksonnet/jsonnet
    - Kapitan (замена Helm)
    Если что-то пошло не так - надо делать kubectl rollout.
  
    Не-kubectl-based
    
    - Helm - рендерит манифесты, сохраняет в артефакты (2 версия в ConfigMap, 3 версия в Secret). Версионирование также в секретах, если надо откатиться - берется предыдущий секрет.  
      Это "пакетный менеджер" - разруливает зависимости.  
      CNCF - одобренно федерацией Cloud Native  
      Декларативный  
      Состоит из Heml+Tiller (v2), Tiller - серверная часть, ставился с большими привилегиями, в v3 Tiller выпилили.  
      Есть важные фичи для построения CI/CD:  
    
      - watch
      - rollback
    
      Система плагинов: например Helm-monitor, который может делать проверку выкатку релиза.

Пакет:
  - набор темплейтированных манифестов
  - файл со значением переменных
  - метаданные
  - все упаковывается в .tgz и обзывается чартом

Команды:
  - `helm search` – поиск чарта
  - `helm install` – установка чарта
  - `helm upgrade` – обновление чарта
  - `helm get` – скачать чарт
  - `helm show` – показать инфу о чарте
  - `helm list` – список установленных чартов
  - `helm uninstall` – удалить чарт

Тестирование релизов при помощи Helm:
  1. Создаем папку templates/tests/
  2. Кладем туда манифесты объектов k8s которые будут тестить релиз
  3. Манифесты должны содержать аннотацию `helm.sh/hook: test`
  4. Запускаем в CI `helm test <release name>`

Хуки в Helm
  - pre-install, post-install, pre-delete, post-delete, pre-upgrade, post-upgrade,
pre-rollback, post-rollback
  - Это те же манифесты k8s
  - Одинаковые хуки сортируются по весу и имени объекта
  - Сперва отрабатывают объекты с меньшим весом (от - к +)
  - Хуки не входят в релиз (helm.sh/hook-delete-policy)

Свой репозиторий Helm
  - можно хранить в гите
  - можно сделать хоть на Nginx - должен быть HTTP сервер, умеющий хранить YAML и TAR, где в нужной структуре лежат чарты, архивы и контрольные суммы. 
  - в корневой директории должен быть файл index.yml с индексом всех чартов
  - самый простой репозиторий - это Nginx


Разные полезные команды Helm:
  - Поиск чартов
    `helm search hub`
  - Получение дефолтных values
    `helm show values repo/chart > values.yaml`
  - Установка чарта в кластер
    `helm install release-name repo/chart [--atomic] [--namespace namespace]`
  - Локально отрендерить чарт
    `helm template /path/to/chart`

Холиварные вопросы:
  - где лучше хранить чарты Helm? Вместе с кодом или отдельно? 
      - Если хранить в отдельном репозитории - то у всех разработчиков будет единообразное восприятие чартов. 
      - Если несколько команд делают примерно одно и то же - отдельная репа позволит избежать лишних велосипедов. 
      - Если включены автотесты - то каждое изменение чарта ведет к запуску цикла тестов. Тут надо смотреть, что изменяется чаще - код или Helm chart. 
  - как версионировать чарты?
  - если туча микросервисов - не лучше ли чарты вынести в другую репу?

Helm Linter - проверяет на синтаксис и на bad practices. 
  - команда `helm lint`

    

## Тема №7: Ceph, установка в режиме делай как я. Работа с постоянными томами, sc, pvc, pv, подключение томов к подам. Разбор на примере Ceph

**Типы томов**

  - configMap
  - emptyDir
  - hostPath
  - secret

В чем проблема:
  - тома надо делать руками
  - параметры доступа надо прописывать для каждого тома и пода
  - для смены типа подключенного тома - надо менять манифесты 
  - много ручной работы если кластер переезжает

`EmptyDir` - это каталог-заглушка, который существует только пока живет под.

Используется для временных неперсистентных данных. Используется часто в Helm chart-ах как тип тома для хранения данных по умолчанию.

`Storage Class` - хранит параметры подключения

`PVC` - описывает требования к тому

`PV` - хранит параметры и статус тома

`Provisioner` - параметры StorageClass, плагин для создания томов

**CSI - Container Storage Interface**

  - унифицированный интерфейс хранилищ
  - драйверы стоят на хостах и общаются с СХД по стандартным протоколам. Состоят из node plugin+controller plugin
  - node plugin - запущен на каждом узле, работает как Daemon Set, монтирует диски на узел и передает точки монтирования kubelet-у
  - controller plugin - занимается всеми прочими вещами с СХД - ресайз, создание/удаление томов итд 

**CEPH CSI**

  - динамически провижионинг RWO/RWX
  - создание снапшотов
  - ресайз (только увеличение)
  - квоты
  - метрики для мониторинга
  - topology aware - возможность помечать какие узлы в какой зоне доступности, чтобы не гонять лишний трафик репликации.

RBD - исторически работали в режиме RWO.\

**Сервисы CEPH:**

  - mon - мониторы
  - mgr - управляющая нода
  - mds - метаданные
  - osd - где хранятся данные

**Placement Group (PG)** - единица хранения информации. Данные перемещаются кусками в размере PG.



## Тема №8: Установка cert-manager

**Подключение в Ingress**

  - можно создать объект типа Certificate, прописать в нем все домены итд. Прописываем issuer который нам надо. Как только создадим такой объект - certManager увидит новый объект и создаст серт. Это тяжело, так как надо отслеживать 2 объекта.
  - выпуск сертификата по аннотациям в самом Ingress. 

**Basic авторизация в дефолтном ингрессе:**

(type of authentication)

    nginx.ingress.kubernetes.io/auth-type: basic
    # name of the secret that contains the user/password definitions
    nginx.ingress.kubernetes.io/auth-secret: basic-auth
    # message to display with an appropriate context why the authentication is required
    nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required - foo'

## Тема №9: Обслуживание кластера

Проблемы при обновлении:
  - устаревшие версии манифестов (например `deprecated: extensions/v1beta1`)
  - устаревшие ключи запуска при обновлении версии K8S (например фича вышла из статуса экспериментальной и из ключа удалилось ключевое слово experimental)
  - измененные опции (`kubeadm alpha phase`)
  - исправленные ошибки (в старой версии валидация могла проходить, в новой - уже нет. )
  - обновление Docker (разные версии K8S тестируются с разными версиями Докера). Поэтому на новой версии K8S надо сразу смотреть и приводить в соответствие версии Докера.

Порядок обновления:
  - изучаем change log
  - устанавливаем тестовый кластер
  - обновляем тестовый кластер
  - деплоим тестовые манифесты нужного приложения или нескольких, проверяем работу
  - планируем время обновления
  - делаем бекапы
  - обновляем прод по одной ноде
  - после каждой ноды проверяем работоспособность

Что обновляем:
  - etcd
  - Control Plane: API, controller-manager, scheduler, kubelet
  - kubelet on workers
  - kube-proxy
  - kube-flannel
  - core-dns, nodelocaldns
  - ingress
  - certificates


## Тема №10: Практическая работа, докеризация приложения и запуск в кластере

**Helm** применяет манифесты и всё. Поды поднялись, хелм отработал. А дальше уже то что поды не переходят в Ready - проблема не хелма.

Helm заканчивает работу тогда, когда поды в нужном количестве переходят в статус `Running`.

При этом поды могут не переходить в `Ready` из-за неудачных `Readiness/Liveness` проб.


# Kubernetes (Slurm Mega)

## Kubeadm

Сдвиг на managed-решения в публичных облачных провайдерах.
Обычно после опыта с kubeadm люди начинаются смотреть на автоматические или полуавтоматические решения в AWS или GCP вместо развертывания on-premises.

### HA Архитектура

**Stacked ETCD-кластер** - от 3 инстансов ETCD на разных узлах.  

**HA кластер - компоненты есть на каждой ноде:**

  - apiserver
  - controller-manager (изменение объектов в кластере) - работают не параллельно а 1 экземпляр
  - scheduler (распределение подов по узлам) - работают не параллельно а 1 экземпляр
  - база etcd

Нужно нечетное число нод, так как нужен кворум. 5 нод переживают выпадение 2 нод из кластера.

Согласование по алгоритму RAFT.

Работает нормально только при быстрой сети и небольшому числу членов - 3-5 оптимально.

Синхронная запись.

**API Server** - единственный компонент в кластере K8S который работает с ETCD. Его задача принимать запросы от разных источников, записать в ETCD, прочитать из ETCD и т.д.

Kubeadm создает и запускает ноды по одной штуке, на каждой новой ноде нет информации о том, сколько узлов и как уже поставлено. 

На каждой новой ноде локальный API Server работает только с локальным ETCD, пока кластер полностью не собрался. 

**Load Balancer** - распределяет запросы на несколько API Server-ов.

Авторы kubeadm считают, что все люди живут в облаках и по кнопке могут создать экземпляр балансера в облаке типа Amazon ELB.

Если развертывать on-premise - то надо балансер поднимать самому, делать отказоустойчивым, и настраивать.

**Зачем нужен вообще нужен балансер?**

За все время разработки <u>kubelet и kube-proxy не научились внутренней балансировке (software LB)</u>, то есть возможность обращаться по нескольким адресам API. Если указывать локальные адреса, то при падении ноды эти компоненты не смогут обращаться на другие мастер-ноды. 

Более надежная схема - это поднимать балансер на каждой воркер-ноде. 

Controller-Manager, Scheduler - работают в 1 экземпляре, остальные ждут в горячем резерве. Создается объект типа Endpoint, в который пишется аннотация, когда объект последний раз обновлялся. Если прошло больше 5с с последнего обновления, то поднимается экземпляр на другой ноде.


### Что такое Kubeadm

Не умеет ходить на мастера, надо ходить самому по SSH.

Позволяет настроить и запустить все основные компоненты кластера.

CNI надо ставить самостоятельно - базовые типа bridge, host + дополнительные типа calico, flannel.

Управляет сертификатами.

Делает апгрейд или даунгрейд.

<u>Kubeadm - не является готовым инструментом деплоя кластера</u>. Он является строительным блоком для создания полноценных систем управления кластером.

В зависимости от требований - надо либо немного либо много ручного труда. 

Ранее у всех узлов кроме самого первого - были серты, которые продлевались автоматически. На первом узле надо было продлевать руками.

Сейчас все серты автоматически ротируются. 


### Создание master-нод

Порядок установки:
  - Ставим Docker
  - Отключаем в настройке docker IPTables.
  - Настройка `sysctl`, отключение SELinux
  - Установка бинарников `kubelet`, `kubectl` и `kubeadm`
  - настройка манифеста ControlPlaneEndpoint, указание IP-адреса для первого мастера
  - создание кластера (`kubeadm init`)
  - копирование токена и ключа сертификата
  - установка сетевого плагина (calico)
  - копирование kubeconfig в ~/.kube/config:
    `cp -i /etc/kubernetes/admin.conf $HOME/.kube/config`

Init-контейнеры в CNI делают некоторую магию :)

Добавляют на ноды бинарники, файлы настроек, после которых начинает работать overlay-сеть.

Плагин за сеть внутри контейнера и плагин за связность узлов по оверлей-сети.

Добавляются CoreDNS, kube-proxy (создает IPVS, IPTables-правила)

`kubectl get nodes` выдает не версию кластера, а версию kubelet на нодах!

Авторы kubeadm любят calico и не любят flannel, хотя последний это stable продукт, готовый к пром эксплуатации.

Мастера надо установить за час, иначе протухнет инициализирующий сертификат! (TLS Bootstrap)


### Добавление worker-nod

Порядок установки:
  - Ставим Docker
  - Отключаем в настройке docker IPTables.
  - Настройка sysctl, отключение SELinux
  - Установка бинарников kubelet, kubectl и kubeadm
  - копирование токена
  - проставление лейблов для нод node-role.kubernetes.io/node=""

Worker-ноды можно добавлять одновременно в несколько потоков.

Обновление версий kubelet, kubeadm и kubectl - просто установкой yum-пакетов и затем:

`sudo systemctl restart kubelet && sudo systemctl daemon-reload`


### Добавление ингресс-контроллера и тюнинг CoreDNS

По умолчанию CoreDNS не проставляет `PodAntiAffinity`, и два пода CoreDNS могут сложиться на одном мастере. Если мастер упадет, то будет 5-минутный таймаут, пока поды не перезапустятся.

Если не хочется заморачиватсья с PodAntiAffinity, то один из подов можно просто убить и он поднимется на другом узле.

Рекомендации по добавлению в `values.yaml`:

//Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/

```
config:
  map-hash-bucket-size: "128"
  proxy-buffer-size: 16k
  server-tokens: "false"
  skip-access-log-urls: /health,/healthz,/ping
  worker-shutdown-timeout: "30"
```

**Nginx ingress controller:**

  - Ставим через Helm
  - Отключаем серверные заголовки
  - Не логируем health check
  - Включаем hostNetwork
  - По желанию включаем метрики


CoreDNS в проде лучше ставить через Helm Chart. Если хелма нет - затащить его внутрь.

Проблема с 8 запросами к CoreDNS: любой запрос к CoreDNS 

В файле `/etc/resolv.conf` указываются по умолчанию search-домены.

По умолчанию сервис разворачивается с svc.cluster.local, чтобы работали локальные запросы.

Проблемы начинаются когда из подов выполняются запросы на внешние ресурсы - для серверов в домене .ru выполняется аж 8 DNS-запросов.

Например первый запрос на ya.ru выполняется на ya.ru.default.svc.cluster.local, потом на ya.ru.svc.cluster.local и так далее.

Это лечится функцией autopath в CoreDNS.

Делаем:

`kubectl edit configmap -n kube-system coredns`

Там добавляем:

```
autopath @kubernetes
      kubernetes cluster.local in-addr.arpa ip6.arpa {
         pods verified
         fallthrough in-addr.arpa ip6.arpa
         ttl 30
      }
```

**Autopath** добавляет дополнительный запрос во внешний мир и возвращает запись CNAME с именем в запросе и IP-адресом, который вернул внешний сервер.

Использовать стоит всегда, если на каждой ноде не стоит кэширующего DNS.

Namespace с именем ru или com создавать не стоит :)

Полезные параметры кубелета в проде:

- `--cpu-manager-policy=static` //если реквесты и лимиты одинаковые и число является целым - под не будет эвиктиться, если для его запуска хватает ресурсов. Файл `/var/lib/kubelet/cpu_manager_state` определяет число CPU на момент последнего запуска кубелета. Если на узле надо добавить ядер - этот файл надо удалить.
- `--eviction-hard=memory.available<1Gi` //хард-лимиты для начала эвикта подов. Значение здесь будет зарезервировано плюс к системным резервам и резервам кубелета.
- `--eviction-minimum-reclaim=memory.available=2Gi` // после принудительного эвикта когда начать запускать новые поды, по какой границе свободной памяти
- `--eviction-max-pod-grace-period=30` //сколько секунд будет ждать кубелет до завершения приложения перед эвиктом
- `--system-reserved=memory=1.5Gi,cpu=1` //сколько ресурсов оставить под систему на ноде, как минимум для docker
- `--kube-reserved=memory=512Mi,cpu=500m` //сколько ресурсов откусить чисто под kubelet - будут вычитаться из тех что отрапортует scheduler. Kubelet будет запускаться в отдельной Cgroup.

Поды типа guaranteed эвиктятся самыми последними с узла.

До них - поды с реквестами равными лимитам.

До них - поды с реквестами меньше лимитов. 

На каждый pod создается cgroup в ядре, и дальше ядро занимается учетом и лимитированием ресурсов.

Добавление в `k8s_completion.sh` строк для алиаса:

```bash
`alias k=kubectl
if [[ $(type -t compopt) = "builtin" ]]; then
    complete -o default -F __start_kubectl kubectl
    complete -o default -F __start_kubectl k
else
    complete -o default -o nospace -F __start_kubectl kubectl
    complete -o default -o nospace -F __start_kubectl k
fi
```

Второй способ - добавить в `~/.bash_profile`:

```bash
source <(kubectl completion bash)
alias k=kubectl
complete -o default -F __start_kubectl k
```




### Аутентификация

Запрос к API -> 

пользователь есть в базе? тогда идем в авторизацию -> 

Проверяем тот ли пользователь за кого себя выдает (авторизация) -> 

Admission Controller (RBAC), проверяем роли в кластере -> 

пускаем в API (доступ) -> 

запись в ETCD 



Всё что стучится в API - проходит эту цепочку.

Аутентификация - через плагины, в базе их около 6 штук. 
Если хотя бы один из плагинов смог аутентифицировать пользователя - переход к авторизации.

**Способы аутентификации:**

  - сертификаты (по умолчанию серт зашит в `~/.kube/config`). Из коробки нет механизмов отзыва, управления жизненным циклом. Есть способы генерации CRL, но сложно настраивать.

  - файл с токенами или пользователями (локальная база на мастерах). Проблемы все те же самые, что с сертификатами + поддерживание консистентности между разными файлами на мастерах. Востребовано только в лабах. 

  - service account - хорошо подходит для приложений внутри кластера, но плохо для внешних пользователей. "Аутентификация для бедных" - самый простой способ, который позволяет отзывать и ротировать токены. Токен валидируется корневым сертификатом кластера. <u>Токены по сути это JWT</u>. Под НЕ запускается от сервис-аккаунта. <u>Под ассоциируется с сервис-аккаунтом</u>. Если не указать сервис-аккаунт - то присвоится default, который есть в каждом неймспейсе. В каждый под монтируется секрет сервис-аккаунта (`/var/run/secrets/kubernetes.io/serviceaccount`), что удобно для сторонних библиотек. Способ хорош для небольших сетапов.

  - Auth proxy - запросы отправляются не в API Server напрямую, а в некую прослойку. Токен валидируется на внешнем сервере. В этом случае API Server выполнять будет только авторизацию. Kube API принимает запросы только от сервиса аутентификации со специальным сертификатом. Пользователь СРАЗУ ходит на внешний ресурс для авторизации.

  - Webhook - взаимодействие только по HTTPS с отдельным приложением, которое выполняет аутентификацию. Нужно подменять конфиг-файл на мастерах: `cp auth-config.yml /etc/kubernetes`. Вебхук встроен в Kube API Server, то есть пользователь идет по СТАНДАРТНОМУ адресу API и тот его прозрачно пробрасывает на приложение аутентификации. Запросы направляются напрямую в Kube API Server. Возможность ротации паролей, отзыв учетных записей (если это поддерживает источник учетных записей). 

      Подходит для GitHub, GitLab. 

  - OIDC Dex: Пользователь приходит на UI Gangway -> Dex генерирует токен и передает его на авторизацию в kube-api -> доступ по id токена. Gangway умеет сама ходить в Dex за новыми токенами, если токен истек. Это первое решение, в котором из коробки работает ротация токенов. По умолчанию токены выпускаются на сутки. По умолчанию плагин для аутентификации с использованием OIDC выключен, для его включения необходимо внести изменения в настройки kube-api. Настройки kube-api сервера генерируются из Сonfigmap kubeadm-config каждый раз при обновлении кластера с использованием утилиты kubeadm. Есть интеграция с многими системами, в т.ч. AD. Подходит для прома, но ограничена кастомизация. 


## Kube-net и Network Policies

<u>Сетевые политики - кластерный фаервол</u>. Через YAML-манифесты указывается, кто и куда может обращаться внутри кластера. 

Если кластер для одной группы пользователей и вообще не multi-tenant - то в принципе сетевые политики особо не нужны.

Контейнеры подключены к сети хоста через бридж. Veth-пара это виртуальный патчкорд, который одним концом торчит в сети хоста (root namespace), вторым в сети пода (pod namespace)

Все адреса подов на одном хосте - сидят в одной сети.

Трафик подов между узлами ходит через оверлей-туннели. 

Сам K8S не занимается созданием сети.

Исполняемая среда контейнеров -> CNI -> плагины CNI (Loopback, IPvlan, ...)


### Сетевые плагины

Кубелету можно сказать про плагины через опции:
  - `--network-plugin=kubenet` (встроенный)
  - `--network-plugin=cni` (через плагины)
  - `--cni-bin-dir=/opt/cni/bin` (бинарники плагинов)
  - `--cni-conf-dir=/etc/cni/net.d` (конфиги плагинов, по факту кубелет использует один файл)

**Основные CNI плагины:**

  - Calico - L2, BGP, IPIP, vxlan, Network Policy. Много умеет. Заточена под большие кластеры (50-100 узлов и больше). Роутинг через BGP плюс возможность анонса маршрутов на внешние BGP-роутеры. В будущем будет поддержка шифрования повех wireguard-туннели (вместо vxlan)
  - Flannel - L2, IPIP, vxlan, IPSec, частичное шифрование (strongswan), но нет Network Policy. Просто настраивать. 
  - Canal (Calico + Flannel) - L2, IPIP, vxlan, Network Policy. Не самостоятельный плагин. 
  - Weave Net - vxlan, Network Policy, шифрование

Calico IPIP mode - это когда стоит заворачивать трафик в туннель
  - Never - никогда
  - Always - по умолчанию
  - Cross Subnet - только если получатель и отправитель не в одной LAN.

`calicoctl get ippool -o yaml` показывает эти настройки.
`calicoctl get nodes -o wide` - показывает какие адреса и с какой маской плагин знает. 

В calico больше крутилок для тонкой настройки под конкретные сетевые окружения.


### Network Policies

"Запрещено всё, что не разрешено" - если у пода нет политики, то к нему ходит трафик без проблем. Если политика есть - то ходит только тот трафик, который описан в политике. 

Создается YAML-манифест, в котором описывается, к чему он применяется

Политика, которая запрещает всё:
  - `spec:podSelector:matchLabels: {}`

Если указываем например policyTypes: - Ingress и не создаем блок spec:ingress - то запрещается весь входящий трафик!

Можем дополнительно указывать порт и протокол в правилах политики.

Пример:

```yaml
spec:
  policyTypes:
    - Ingress
    - Egress
    - Ingress,Egress
  ingress:
    - ports:
    - port: 53
      protocol: UDP
    - from:
  egress:
    - ports:
      to:
        ipBlock:
          cidr:
          except:
        namespaceSelector:
          matchLabels: {}
        podSelector:
          matchLabels:
            run: access
```

Network Policy под капотом - это куча правил IPTables.

Если в NetworkPolicy нет `namespaceSelector` - то разрешающее правило разрешает доступ только из подов в том же namespace

Если в NetworkPolicy есть `namespaceSelector` - то правило разрешает доступ только из подов в namespace, попадающих под выборку

Как много делать политик? Зависит от требований безопасности.

Стоит как минимум ограничивать доступ в системные неймспейсы.


## Безопасность и высокая доступность приложений

https://github.com/stakater/reloader - проект контроллера, который смотрит за изменениями в ConfigMap/Secrets и делает Rolling Update деплойментов, которые зааффекчены.

### Безопасность контейнеров

Docker - не средство контейнеризации (в отличие от containerd, crio), а скорее аналог пакетного менеджера, стандарт упаковки и доставки приложений.

Поэтому Docker сам по себе - не про безопасность.

Что умеет ядро - то умеет и Docker:

  - Namespace isolation
  - Resource isolation (CGroups)
  - GID/UID
  - Kernel capabilities
  - Image security

С приходом K8S возможность выстрелить в ногу выросла. Это дополнительный слой над Docker.
  - host namespace
  - root user
  - privileged
  - host path volumes - самое плохое. Можно утащить сертификаты хоста, /etc/passwd, и так далее...



### PSP - Pod Security Policy

Контролирует аспекты безопасности в описании подов - что они могут в рамках Namespace (доступ к HostPort, HostNetwork и т.д.) 
Включается как Admission Controller Plugin "PodSecurityPolicy" - и при включении запрещает запуск подов без PSP.

Что значит валидация PSP?
  - под и пользователь который запускает под - оба получили OK от Admission Controller, что под можно запускать

Без PSP можно подмонтировать в под hostPath вплоть до корня (доступ к паролям и сертификатам), а с опциями:

```
hostNetwork: true
hostPID: true
```

можно получить доступ к хостовой сети (снифф трафика) и хостовым процессам.

Сперва создаем объекты PSP в кластере! А затем уже контроллером включаем PSP (иначе будут проблемы с запуском подов)
Включение Admission Plugin - это надо добавить нужную опцию в ConfigMap kubeadm-config:

```yaml
kubectl edit configmap --namespace=kube-system kubeadm-config

data:
  ClusterConfiguration: |
    apiServer:
      extraArgs:
        enable-admission-plugins: PodSecurityPolicy
```

**ВАЖНО!** PSP валидирует только поды, которые будут запускаться! Если под уже запущен - на него созданные PSP никак не повлияют!

Теоретически PSP может контролировать и доступ к PVC определенного StorageClass, то есть можно запретить например доступ подам к быстрым дискам.

## Доступность приложения в K8S

Что может повлиять на доступность приложения? (в основном)
  - выход ноды из строя или нескольких нод
  - удаление приложения
  - технические работы на кластере

Что делать?
  - избыточность - не нужно делать 1 под на приложение + нужно постоянно иметь запас в кластере по ресурсам и по вычислительным нодам
  - мониторинг - заранее видеть когда кончатся ресурсы или когда кластер сломается
  - аккуратность - минимизация риска человеческого фактора

## Сетевые абстракции

### Service vs Ingress

**Service** - это просто IPVS/IPTables, который генерируется на всех нодах кластера + Service Discovery на основе DNS. С IPTables есть проблемы на уровне NAT.

**Ingress** - это а) Next Upstream + возможность retry запроса на другой backend, b) SIGTERM trap (pre-stop hook)

Retry можно только идемпотентные запросы. Это было актуально до распространения Service Mesh.

**Service Mesh** - не панацея, это довольно узкая штука для решения конкретных проблем, и при этом несет большой оверхед своими сайдкарами и остальным.

Ingress - если нет возможности повторять неуспешные запросы при межсервисном взаимодействии (этим будет заниматься ингресс)


### Pod Disruption Budget

Ограничивает число инстансов, которые могут быть недоступны одновременно

Администратор должен при этом использовать Eviction API. 

Мешает работе с кластером и не дает делать Drain (например при обновлении кластера, Rolling Update, итд)

PDB влияет только на запросы через Eviction API

По сути PDB - это минимальное количество реплик пода.


### Limitrange, resourcequota

Limitrange - устанавливает ресурсы для объектов кластера - дефолтные, минимальные и максимальные.

Для контейнеров, для подов и для PVC. 

Дебильный синтаксис:

```yaml
  default: // это про лимиты
  defaultRequest: // а это про реквесты
```

**Resourcequota** - namespace-зависимый объект, устанавливает кол-во доступных ресурсов и объектов в NS:

  - реквесты
  - лимиты
  - сервисы
  - поды

Дебильный синтаксис:

```yaml
  hard: // "жесткие" лимиты. А мягких нет.
```




### Priorityclass

Устанавливает разные классы для подов с точки зрения важности для Sheduler-а. 

Если нужно эвиктить поды - в первую очередь выводиться будут поды наименее приоритетных классов.

По приорити классам можно разделять ресурсы в квотах.

Единственное значение в PC - это Value. Чем больше значение Value - тем более приоритетный класс.


## Kubernetes изнутри

### Запуск приложения:

  1. User создает RS -> Kube API
  2. Валидация манифеста -> проверки со стороны ETCD -> запись в ETCD
  3. отчет пользователю о том, что манифест сохранен в постоянное хранилище (RS created)
  4. Controller Manager подписан в ETCD и следит за созданием новых объектов (RS) и начинает генерить манифесты подов
  5. аутентификация -> авторизация -> валидация -> запись в ETCD
  6. планировщик подписан на события New Pods и создает объект Bind Pods (не изменяя при этом манифесты подов!) 
  7. kubelet подписан на Pods Binding, стучится в docker на своей ноде через GRPC, тот запускает контейнеры в подах.
  8. у kubelet есть PLEG - Pod Lifecycle Event Generator - отслеживает события в докере и отправляет в API Server. Это показывает статус подов (Pending, Creating, Error итд) и отправляет его обратно в KubeAPI и соответственно из API запись событий в ETCD.

Если создается отдельный под и он не запускается по PSP - будет ошибка при создании пода.

Если под PSP попадают деплойменты или RS - то манифесты этих объектов будут сохранены в ETCD. И уже когда манифесты подов будут генериться - только тогда будет ошибка.  

В describe деплоймента ничего не будет, так как поды создает RS! И в описании RS будет сообщение о том что поды попали под PSP и не создались.

Чтобы починить сломавшийся кластер - не надо лезть в ETCD пока кластер еще подает признаки жизни!

Надо по максимуму пользоваться инструментами самого K8S.

Finalizers - набор действий в кластере K8S до того, как объект будет считаться удаленным.

### Scheduler

Отслеживает объекты типа Pod у которых `spec.nodeName=""`.

После этого получает список нод и начинает фильтровать те, которые не подходят по селекторам, Affinity, Taints, Resources, Plugins.

Далее идет оценка нод, какие больше всего подходят для запуска пода (`Scoring`).

Оценка идет по совокупности параметров, каждой ноде добавляются очки за каждый параметр.

Нода с максимальным числом баллов суммарно - выбирается для запуска пода. Если несколько нод с одинаковым количеством баллов - нода выбирается рандомно.

После этого - еще раз валидация Pod Binding и финальная проверка ноды - а работает ли она еще и готова ли принимать поды?

Фильтрация и скоринг реализована по отдельным плагинам, и можно 

- а) влиять на оценку и поведение каждого плагина, 
- б) включать/отключать какие-либо плагины.

Таким образом можно влиять на логику работы планировщика.


### Controller

Ключевой компонент - `SharedIndexInformer`.

Он подписывается на все обновления в кластере и тянет их к себе.

При появлении обновления он берет его и отправляет в Indexer. 

Indexer отправляет его в локальное Key-Value хранилище (key - хэш, value - манифест). Фактически это локальный кусок копии ETCD.

Если объект относится к данному контроллеру - тот берет его ключ из хранилища и ставит его в очередь обработки (WorkQueue)

Если в очереди есть объекты - то процесс (Process) забирает объект из очереди. Если в процессе работы ошибка - ключ возвращается в очередь.

Иногда разрабы хотят работать с KubeAPI, но игнорируют готовые библиотеки. Есть резон им показать то, как работает сам K8S.


### Controller-manager

Смотрит за появлением новых объектов в Kube-API - у которых `spec.replicas != status.replicas`.

Как только объекты появляются - создает поды до появления нужных реплик.

Параллельно работает `Admission Controller`:

  - Mutating Web Hooks - хуки, изменяющие свойства объектов (например Istio, Vault)
  - Schema Validation
  - Validation Web Hooks (отправка определенных объектов на запущенный сервис внутри кластера)
Если Admission Controller за время в timeoutSeconds не ответил - то идет переход к следующему вебхуку в списке, если он есть. 

Вебхуки - единственный способ запретить запускать приложения в кластере, которые не нужно чтобы в нем запускались :)


### Custom Resource Definition

**CRD** - способ создания своих объектов в кластере K8S

  - позволяет создавать новые объекты типа Custom Resource
  - настраиваемый вывод в kubectl get
  - настраиваемая валидация
  - обрабатывается операторами

Аналогия: в мебельный магазин привезли кучу новых столов, требуется составить каталог по определенным характеристикам всех новых столов. 

Набор характеристик в описании каждого стола + формат каждой характеристики - это и есть CRD.

Контроллер, который умеет работать с CRD - это **ОПЕРАТОР**!

Разница между контроллерами и операторами - только в том, что <u>контроллеры работают со встроенными объектами.</u>

Что делает оператор:
  - watch Kube API (отслеживание создание "своих" объектов)
  - локальная K-V база
  - скорее всего пишется на языке Go (через Operator SDK) и работает в кластере:
    - создание нового проекта с SDK Command Line
    - создание CRD
    - пишется логика обработки CRD
    - с помощью SDK CLI собирается оператор в образ Docker
    - деплой в кластер
  - работает по стандартному циклу контроллеров
  - помимо Go можно реализовать с помощью Helm Template (частично) и с помощью Ansible Role

Рекомендация - ставить любой сторонний софт в кластер K8S в отдельные Namespace.

Таким образом, удаляя Namespace - гарантированно удаляются все ресурсы.


## Stateful-приложения

Почему нельзя Deployment?
  - RS назначает случайные суффиксы именам подов
  - конфиг всех подов одинаковый
  - нельзя задать отдельный том для каждого пода
  - поды создаются в произвольном порядке - неизвестно, какой под когда стартанет
  - доступ извне через сервис к случайному поду (ломается схема - доступ на мастер БД для записи, на реплики на чтение)

Есть нормальные способы:
  - Использовать PV/PVC
  - StorageClass/StorageProvider
  - StatefulSet
  - CEPH, RBD, NFS, ...
  - Operators
  - ...

**Почему БД не нужно пихать в K8S?**

  - СХД - нельзя одновременно (надежно, быстро, дешево).
    - LocalVolume - быстро но нет HA
    - Диски облачных провайдеров - медленно
    - готовые железки с операторами под них (NetApp, EMC) - круто но дорого
    - свой SDS - мало спецов, надо собирать грабли несколько лет. CEPH самое зрелое хранилище, но оно про надежность а не про скорость
  - Настройка и управление 
    - init-контейнеры - куча bash-изма, как в монолитах
    - entrypoint-скрипты - куча bash-изма, как в монолитах
    - выделение ресурсов
  - стабильность Docker
    - надо резервировать ресурсы под сам демон (БД съест всю память на ноде, а докер плохо работает если осталось мало ресурсов)
    - проблемы с кол-вом контейнеры
  - переключение при аварии и fencing
    - service labels - медленно (10-15 секунд это критично)
    - проблемы с split brain
    - операторы не все умеют fencing из коробки

**Stolon - cloud-native manager для PostgreSQL**

  - оператор
  - готовый Helm Chart
  - использует потоковую репликацию Postgres
  - автоматическая настройка
  - асинхронные и синхронные реплики
  - Point-in-time recovery
  - состояние умеет хранить в ETCD, Consul, Kube API
  - pg_rewind для быстрой повторной синхронизации если один мастер потух и потом вновь вошел в кластер

**Percona XtraDB + MariaDB** - решение для MySQL. Если надо MySQL - не ставить ваниллу, а ставить этот форк либо Vitos.

**Galera** - платная подписка.

MongoDB (NoSQL) - меньше проблем чем с MySQL и Postgres.  
Поставляется готовым Helm Chart-ом, и как бы работает. 

**Redis** и **Memcached** (In-Memory) - раньше были проблемы, сейчас более-менее с кластеризацией нормально. 

**Rabbit** - норм

**ETCD** - отлично но нужны быстрые диски и толстый линк

**ElasticSearch** - подходит но жрет много ресурсов, и CPU/RAM и диск, сам умеет ребаланс.

**CockroachDB** - прекрасно но есть нюансы

  - из коробки отказоустойчивость, реляционность, распределенность
  - алгоритм RAFT (как ETCD)
  - реплика кусками по 64МБ
  - RocksDB для хранилища
  - SQL API на основе PostgreSQL
  - деплой в пару команд
  - хорошая интеграция с K8S
  - хорошая документация и удобная админка
  - не подходит под объемы >500GB
  - не дает много QueriesPerSecond
  - большие индексные ключи ухудшают производительность
  - мало пространства для тюнинга

Плюсы деплоя Stateful в K8S:
  - IaC с оговорками
  - нет вендорлока
  - единый стандарт архитектуры
  - стильно модно молодежно, хипстерно
  - быстрый scale реплик и быстрое развертывание

Минусы:
  - куча новых абстракций
  - повышенные требования к знаниям (DBA + DevOps)
  - персистентность - как хранить данные
  - проблемы динамических конфигураций - операторы и вот это всё
  - мало нормальных рабочих операторов/решений, готовых для прода
  - Resource Management

## Секреты

Что кладут в секреты?
  - логины-пароли
  - токены
  - ключи сертификатов

Как создавать секреты?

```yaml
kubectl create secret generic <secret_name>
--from-file=
--from-literal=
--from-env-file=
```

Кодируются в base64. Не зашифрованы по умолчанию.
Монтировать либо как файл либо как переменные окружения.

Плюсы:
  - деплой через одну точку
  - деплой на нужные узлы по лейблам
  - кладутся в /tmpfs

Минусы:
  - ограничение прав доступа
  - с узла можно получить все секреты
  - хранятся без шифрования (кроме ETCD)

**Hashicorp Vault:**

  - хранение в шифрованном виде
  - разграничение прав доступа
  - аудит доступа
  - ротация секретов
  - есть secret engine - который может менять секреты по расписанию
  - поддержка HA-Storage - либо родной для него Consul либо ETCD 
  - авторы параноики :) защита памяти, чтобы она не попала в swap на диск, и многие другие вещи
  - sealed Shamir - способ получения ключа для расшифровки - в каждый инстанс самостоятельно, нет репликации. Ключ например, делится на 5 частей, и надо чтобы хотя бы 3 из 5 ввели свои части ключа. 
  - sealed Cloud KMS
  - появился недавно встроенный HA Storage

**Как работать с Vault:**

  - из приложения через библиотеки
  - получать информацию из Vault и обновлять секреты в K8S
  - в момент запуска приложения предоставлять ему настройки из Vault вместо создания секретов в K8S. Придумано было в Banzaicloud. Копирование бинарника Vault в EmptyDir() и уже из него берутся настройки приложения. Строка запуска должна быть определена в манифесте, vault-env цепляется через init-container, потом в In-Memory Volume. 
  - у Vault есть Auth-плагины, которые проверяют пользователей через внешние валидаторы. Есть K8S-плагин, в нем в запросе указывается токен от SA. Можно ротировать сертификаты, так как Vault у себя токены не хранит. 


## Horisontal Pod Autoscaling

**HPA** - это контроллер, который говорит деплойментам, увеличивать или уменьшать количество реплик.

За метриками он идет в KubeAPI.

Внутри kubelet зашит компонент, который называется cadvisor. Именно он собирает метрики с контейнеров.

В kube-system есть сервис metrics-server, куда Kube-API проксирует запросы метрик. 

metrics-server в свою очередь умеет ходить в kubelet и собирать информацию.

HPA v1 умеет оценивать только CPU и RAM.

Поддержка metrics server встроена в kubectl (kubectl get top ...)

Метрик-сервер собирает данные раз в минуту.

Это не полноценная система мониторинга! Истории она не хранит и вообще данные не сохраняются, показываются только текущие значения.

При скейлинге вниз HPA начнет убивать поды только тогда, если по подсчетам нагрузка в процентах после прибития пода будет меньше целевой. 

Значение Replicas в Deployment отвечает за первичное кол-во реплик при создании деплоймента. Если включить HPA и значение min в нем будет меньше чем Replicas в деплойменте - то при отсутствии нагрузки поды будут убиваться от изначального значения.
  - maxReplicas, minReplicas - максимальное и минимальное кол-во реплик 
  - kind, name - что скейлим

HPA v2 - появилось поле type.

Объекты метрик:

  - Resource: наследие HPAv1, поддерживает CPU и память. 
    - AverageUtilization - в процентах
    - AverageValue - в абсолютных значениях (в МБ для памяти например)
  - Pod - скейлить от показателей метрик пода, при наступлении целевого значения указанной метрики
    - metric: имя метрики
    - target: type: AverageValue - целевое значение
  - Object - на основании показателей произвольных объектов кластера K8S
  - External - имя метрики и селектор для фильтрации (как в Prometheus)

Prometheus Adapter - отдает метрики Прометея через Kubernetes API.

Для мониторинга кластера нужен сам Прометей + адаптер.

После этого метрики будут доступны в /apis/custom.metrics.k8s.io/v1beta1

При обращении к kube-api на endpoint v1beta1.custom.metrics.k8s.io запросы будут перенаправлены в Service с именем prometheus-adapter в namespace monitoring.


## Бекап

<u>Когда все сломалось - это не бекап-restore, это Disaster Recovery</u>. 

В основном бекапы - защита от дураков, от некритичных сбоев когда пересоздавать реально дольше. Либо для раскатки стейджа или какой другой среды из бекапа.

**Что бекапить в K8S?**

  - манифесты - все манифесты это бекап кластера без данных
  - секреты
  - сертификаты и настройки узлов
  - образы контейнеров
  - содержимое volume-ов
  - базы данных

**Методы и способы бекапа:**

  - IaC - проще создать новый, чем восстанавливать старый. В реальной жизни очень сложно. Мало кто тестирует всесторонне.
  - ETCD snapshot - делается быстро
    - `ETCDCTL_API=3 etcdctl --endpoints <endpoints> --cert "$cert" --key "$key" snapshot save snapshot.db`
    - если данные в ETCD положили по APIv2, при обращении по APIv3 этих данных не будет видно
  - **Heptio Velero** - выбираем придирчиво. Может поменять namespace при восстановлении, storage class-ы, много чего еще. 
    - тот же snapshot но в JSON-объектах
    - изначально разрабатывалась для работы с облаками
    - есть Storage Provider-ы
    - S3-compatible - IBM, Minio, CEPH, DigitalOcean
    - Restic - daemon-set, делающий rsync томов на узле и хранилища на бекап-провайдере. Поддерживается инкрементальный бекап.
    - С версии 1.4 есть поддержка CSI-снапшотов
    - умеет бекапы по расписанию с форматом как в Cron
    - Может менять StorageClass - если в новом кластере нет SC которые были в старом
    - Backup Hooks - команды, которые запускаются перед бекапом (хорошо кладется на restic, можно делать фриз файловой системы, иногда полезно на проде)

Нюансы с Minio: для тех кто еще не сталкивался с minio, там есть грабли с его data dir. если data dir не прям отдельный mount, который можно получить по df -h, то минио будет периодически сканить его с помощью du и если писать много мелких файлов, будет высокая загрузка и OOM из ничего.

Это показывает, что эта штука не для прода. 

Cамый ньюанс именно в том сколько будет файлов - если их миллионы/миллиарды, то du будет годами сканить. В minio поддержка версионирования объектов в бакетах появилась меньше месяца назад.

Minio кладёт все как есть в папку на диске, если underlying fs будет тормозить, minio тоже будет, ребалансировки там нет.


## Ротация сертификатов

**Серты в кластере:**

ETCD
  - server.crt
  - ca.crt - корневой на 10 лет
  - peer.crt - члены etcd ходят друг к другу, 
  - healthcheck-клиент - им пользуется kubelet 

Master
  - apiserver-etcd-client.crt - клиент к серверному серту ETCD
  - front-proxy-ca.crt
  - front-proxy-cluent.crt - для прокси-клиентов
  - ca.crt - подпись остальных сертов, токены для SA
  - apiserver.crt - доп.имена для API-сервера (SAN)
  - apiserver-kubelet-client - клиент к серту кубелетов (запрос логов, состояния итд)

Master clients
  - admin.conf, controller-manager.conf, kubelet.conf, scheduler.conf - конфиги для того чтобы ходить на apiserver на мастере, обычно зашиты в kubeconfig
  - kubelet.crt (серт кубелетов)

Node
  - kubelet.crt (серт кубелета)
  - kubelet-client-current-pem - клиент чтобы ходить на apiserver на мастере

Проверка срока действия:
`kubeadm alpha certs check-expiration`

Обновление (одной кнопкой все серты - в 1.18 работает точно, в предыдущих версиях - не факт):
`kubeadm alpha certs renew all`

Обновление сертификатов отдельных компонентов:

```bash
kubeadm alpha kubeconfig user --client-name kubernetes-admin --org system:masters >admin.conf
kubeadm alpha kubeconfig user --client-name system:kube-scheduler

scheduler.conf
kubeadm alpha kubeconfig user --client-name system:kube-controller-manager >controller-manager.conf
kubeadm alpha kubeconfig user --client-name system:node:kube.s000005.slurm.io --org system:nodes
kubelet.conf
```

Серт для первого мастера выпускается статически и лежит вместе с ключом:

```
client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem
client-key: /var/lib/kubelet/pki/kubelet-client-current.pem
```

При обновлении ноды серты продляются:

```bash
kubeadm upgrade node --certificate-renewal=true
```

После обновления сертов требуется рестарт control plane. С версии 1.17 API-сервер перечитывает серты раз в минуту.


## Деплойменты приложений и шаблоны

### Инструменты темплейтинга и деплоя

У Ansible есть плагин под Кубернетес.

KSonnet/JSonnet, Kustomize, Kapitan - средства темплейтирования. 

Все они передают отрендеренные шаблоны в kubectl, их задача - подставить нужные значения в правильные темплейты.

Их недостаток - использование kubectl. 

Почему плохо? Часто надо быстро откатывать. 

`kubectl rollout undo` - работает только для деплойментов!

Распространение через config map - манифесты можно сжать в архив, перевести в base64-строку и поместить в config map

**Выход - Helm!** 

  - поддерживается версионирование
  - версии хранит в секретах 
  - есть возможности отката
  - умеет следить (watch) приложения
  - идеально ложится на CI/CD
  - третья версия не требует серверного компонента (Tiller) и больше нет дыры в безопасности. 


### Стратегии деплоя

Основные:
  - Recreate - поддерживается деплойментом из коробки
  - Rolling update - поддерживается деплойментом из коробки (используется по дефолту)
  - Blue/green
  - Shadow
  - Canary
  - A/B test

**Rolling Update**

  - технически на уровне ReplicaSet. 
  - создается рядом второй RSv2 при обнаружении апдейта
  - поочередное гашение и поднятие подов
  - поды гасятся и поднимаются строго по одному

**Blue/Green**

  - на уровне Deployment, а не ReplicaSet
  - рядом поднимается новый деплоймент
  - вешаются лейблы на деплойменты
  - labelSelector вешается на сервис
  - селектор меняется в сервисе, чтобы перенаправить трафик

**Canary Releases**

  - похож на Blue/Green
  - канарейка - процент трафика идет в новый деплоймент


## Service Mesh

Модно, хайпово, молодежно.

**Проблемы с монолитами:**

  - сложность внесения изменений
  - продолжительный onboarding
  - низкая отказоустойчивость (я весь упал)
  - сильная связность (легаси)

Переход на слабую связность ведет к тому, что сервисы не знают друг о друге. Проблемы в деталях - вот что неплохо было бы иметь:
  - mtls - общение
  - Auth - аутентификация
  - back-off - переезд сервисов
  - load balancing - на каким инстансы сервиса обращаться
  - service discovery
  - retry
  - throttling - уметь отбрасывать запросы, которые вешают сервис
  - таймауты - когда сервис не справляется
  - chaos monkey - тестирование на устойчивость 

Теперь это задачи инфраструктуры:
  - балансировка запросов
  - ретраи и таймауты
  - контроль доступа
  - авторизация и шифрование между сервисами
  - мониторинг
  - трассировка
  - ...

Какие варианты решения?
  - написать Client-Server Library
    - поддерживать надо для всех языков
    - разное поведение для всех языков, сложно дебажить
    - все равно будут те кто не включит библиотеку в проект
    - добавляет энтропии в проекты
  - Прокси - Envoy
    - для каждого пода
    - написан на C++
    - HTTP/v1, HTTP/2, gRPC
    - продвинутая балансировка
    - поддержка метрик и трассировки
    - быстрый

Service Mesh – это шаблон интеграционного взаимодействия по gRPC в стиле «запрос-ответ»

Istio – это то, что реализует шаблон Service Mesh

Service Mesh – это еще и L7-сеть с технической точки зрения, где вызовы идут в терминах сервисов вместо вызовов в терминах хостов на L3/L4 сетях

Разработчики стоят денег. 

Прикладные разработчики обычно плохо разбираются с сетью и транспортом. Их велосипеды за редким исключением хуже, чем готовая транспортная логика Service Mesh

Переиспользование транспортной логики = экономия времени

TTM продуктов сокращается

Istio – это для эффективных, а не ленивых разработчиков!

Chaos Engineering – чтобы не только на словах, но и на деле:
  - Fault injection
  - Delay injection
Trust-based access control
  - Контроль доступа на базе сетевой телеметрии в реал-тайм


### Архитектура Istio

Установка раньше через Helm Charts, теперь через istioctl - через операторы и CRD.

Сейчас под капотом один Istiod, раньше был Pilot, Mixer, Citadel.

У Istio есть 2 сетевых объекта - один Istio-Gateway, второй VirtualService

Два этих объекта вместе формируют что-то типа ингресса. 


### Сетевые абстракции

**Gateway:**

  - L4-L6 proxy
  - настройка TLS
  - открываются порты и указываются разрешенные протоколы для каждого портаx

**VirtualService** - проверяется матчинг запросов (префиксы, точные пути)

  - L7 proxy
  - пути и направления роутинга
  - кастомная логика
  - failure injection
  - retry
  - ... 

**Destination** Rule

  - настройка политик для трафика после роутинга (какой VirtualService вызывать по нужному URL)
  - методы балансировки
  - версии приложения
  - circuit breakers


### Особенности эксплуатации

То что пишут в рекламе "поставьте Истио и будет вам счастье" - в реальной жизни не работает!
